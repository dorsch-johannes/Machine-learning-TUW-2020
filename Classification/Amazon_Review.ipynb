{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from functools import partial, update_wrapper\n",
    "\n",
    "def wrapped_partial(func, *args, **kwargs):\n",
    "    partial_func = partial(func, *args, **kwargs)\n",
    "    update_wrapper(partial_func, func)\n",
    "    return partial_func\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF,Matern,RationalQuadratic,ExpSineSquared,DotProduct\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "random.seed(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_overview = {}\n",
    "predictions_per_model = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.read_csv('amazon_review_ID.shuf.lrn.csv', low_memory=False, sep=',')\n",
    "df_data_res = pd.read_csv('amazon_review_ID.shuf.tes.csv', low_memory=False, sep=',')\n",
    "\n",
    "class_factor = df_data_train['Class'].factorize()\n",
    "class_index = class_factor[1]\n",
    "\n",
    "\n",
    "df_data_train = df_data_train.replace('?', np.nan)\n",
    "# drop the NaN\n",
    "df_data_train = df_data_train.dropna(axis=0, how=\"any\")\n",
    "\n",
    "output_train=df_data_train['Class']\n",
    "\n",
    "X = df_data_train.drop(labels=['Class'], axis=1)\n",
    "X = X.drop(labels=['ID'], axis=1)\n",
    "\n",
    "X_scale= preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, output_train, random_state = 0, test_size=0.33)\n",
    "\n",
    "\n",
    "df_data_res = df_data_res.replace('?', np.nan)\n",
    "# drop the NaN\n",
    "X_res = df_data_res.dropna(axis=0, how=\"any\")\n",
    "X_res = df_data_res.drop(labels=['ID'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V9991</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9991  V9992  V9993  V9994  \\\n",
       "0  15   2  13   6  11   6   8   2   8    7  ...      0      0      2      0   \n",
       "1  11   9   6  11   4   3   6   5   3    1  ...      1      0      0      0   \n",
       "2  18  10   4   4   8   5   5   6   2    3  ...      0      0      0      0   \n",
       "3  17   6  11   6  11   3   7   4   6    1  ...      0      0      0      0   \n",
       "4  14   9  10  13   8   1   0  12   3    1  ...      0      0      0      1   \n",
       "\n",
       "   V9995  V9996  V9997  V9998  V9999  V10000  \n",
       "0      0      1      0      0      0       0  \n",
       "1      0      0      0      0      0       0  \n",
       "2      1      0      0      0      0       0  \n",
       "3      0      1      0      0      0       0  \n",
       "4      0      0      0      0      0       2  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "output_train.value_counts().plot(kind='bar')\n",
    "plt.savefig(\"output_graphic.jpg\")\n",
    "plt.show()\n",
    "\n",
    "display(output_train.value_counts())\n",
    "display(len(output_train.value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SGDClassifier(),KNeighborsClassifier(),GaussianProcessClassifier(),MLPClassifier(),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X, output_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.savefig(\"Amazon_models.jpg\")\n",
    "plt.show()\n",
    "\n",
    "cv_df.groupby('model_name').accuracy.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "\n",
    "parameter_grid = {\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "cv_grid = GridSearchCV(clf, parameter_grid, cv=3, verbose=10, n_jobs=-1, scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], refit='accuracy')\n",
    "cv_grid.fit(X, output_train)\n",
    "\n",
    "print(\"Best Parameter Choice:\")\n",
    "print(cv_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannesdorsch/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('linearsvc', LinearSVC())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(LinearSVC(loss = 'squared_hinge', penalty = 'l2' ))\n",
    "\n",
    "clf.fit(X, output_train)\n",
    "\n",
    "CV\n",
    "cv_result = cross_validate(clf, X, output_train, cv=3, scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "\n",
    "clf_scaled = make_pipeline(LinearSVC(loss = 'squared_hinge', penalty = 'l2' ))\n",
    "clf_scaled.fit(X_scale,output_train)\n",
    "scaled_acc = cross_validate(clf_scaled, X_scale, output_train, cv=3, scoring = ['accuracy'], n_jobs=-1)['test_accuracy'].mean()\n",
    "\n",
    "results_overview['LinearSVC'] = {\n",
    "    'scaled accuracy' : scaled_acc,\n",
    "    'accuracy': cv_result['test_accuracy'].mean(),\n",
    "    'balanced_accuracy': cv_result['test_balanced_accuracy'].mean(),\n",
    "    'f1_weighted': cv_result['test_f1_weighted'].mean(),\n",
    "    'fit_time' : cv_result['fit_time'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf2 = make_pipeline(LinearSVC(loss = 'squared_hinge', penalty = 'l2' ))\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "results_overview['LinearSVC']['Holdout'] = accuracy_score(y_test,clf2.predict(X_test))\n",
    "\n",
    "display(results_overview)\n",
    "\n",
    "# Predict\n",
    "\n",
    "y_houldout_prediction = clf2.predict(X_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = clf.predict(X_res)\n",
    "f = open(\"linearSVC_amazon_result.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_prediction[i]+'\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(\"linearSVC_amazon_result2.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_houldout_prediction[i]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurs=np.zeros(50)\n",
    "authors=list()\n",
    "\n",
    "for i in range(50):\n",
    "    author=y_prediction[0]\n",
    "    indices=(y_prediction == author)\n",
    "    occurs[i]=np.sum(indices)\n",
    "    authors.append(author)\n",
    "    y_prediction=np.delete(y_prediction,indices)\n",
    "    \n",
    "print(authors)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.bar(authors,occurs)\n",
    "plt.savefig(\"linearSVC_amazon_graphic.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "parameter_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [50, 100, 200, 250]\n",
    "}\n",
    "cv_grid = GridSearchCV(clf, parameter_grid, cv=3, verbose=10, n_jobs=-1, scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], refit='accuracy')\n",
    "cv_grid.fit(X, output_train)\n",
    "\n",
    "print(\"Best Parameter Choice:\")\n",
    "print(cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(LogisticRegression(max_iter= 50, penalty = 'none', solver = 'sag' ))\n",
    "\n",
    "clf.fit(X, output_train)\n",
    "\n",
    "# CV\n",
    "cv_result = cross_validate(clf, X, output_train, cv=3, scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "\n",
    "clf_scaled = make_pipeline(LogisticRegression(max_iter= 50, penalty = 'none', solver = 'sag' ))\n",
    "clf_scaled.fit(X_scale,output_train)\n",
    "scaled_acc = cross_validate(clf_scaled, X_scale, output_train, cv=3, scoring = ['accuracy'], n_jobs=-1)['test_accuracy'].mean()\n",
    "\n",
    "results_overview['LogRegression'] = {\n",
    "    'scaled accuracy' : scaled_acc,\n",
    "    'accuracy': cv_result['test_accuracy'].mean(),\n",
    "    'balanced_accuracy': cv_result['test_balanced_accuracy'].mean(),\n",
    "    'f1_weighted': cv_result['test_f1_weighted'].mean(),\n",
    "    'fit_time' : cv_result['fit_time'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = make_pipeline(LogisticRegression(max_iter= 50, penalty = 'none', solver = 'sag' ))\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "results_overview['LogRegression']['Holdout'] = accuracy_score(y_test,clf2.predict(X_test))\n",
    "\n",
    "display(results_overview)\n",
    "\n",
    "# Predict\n",
    "y_prediction = clf.predict(X_res)\n",
    "y_houldout_prediction = clf2.predict(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"logReg_amazon_result.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_prediction[i]+'\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(\"logReg_amazon_result2.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_houldout_prediction[i]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurs=np.zeros(50)\n",
    "authors=list()\n",
    "\n",
    "for i in range(50):\n",
    "    author=y_prediction[0]\n",
    "    indices=(y_prediction == author)\n",
    "    occurs[i]=np.sum(indices)\n",
    "    authors.append(author)\n",
    "    y_prediction=np.delete(y_prediction,indices)\n",
    "    \n",
    "print(authors)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.bar(authors,occurs)\n",
    "plt.savefig(\"logReg_amazon_graphic.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "parameter_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "cv_grid = GridSearchCV(clf, parameter_grid, cv=3, verbose=10, n_jobs=-1, scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], refit='accuracy')\n",
    "cv_grid.fit(X, output_train)\n",
    "\n",
    "print(\"Best Parameter Choice:\")\n",
    "print(cv_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(RandomForestClassifier(criterion= 'gini',max_features = 'auto',n_estimators=3000))\n",
    "\n",
    "clf.fit(X, output_train)\n",
    "\n",
    "# CV\n",
    "cv_result = cross_validate(clf, X, output_train, cv=3, scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "\n",
    "clf_scaled = make_pipeline(RandomForestClassifier(criterion= 'gini',max_features = 'auto',n_estimators=3000))\n",
    "clf_scaled.fit(X_scale,output_train)\n",
    "scaled_acc = cross_validate(clf_scaled, X_scale, output_train, cv=3, scoring = ['accuracy'], n_jobs=-1)['test_accuracy'].mean()\n",
    "\n",
    "results_overview['RandomForestClassifier'] = {\n",
    "    'scaled accuracy' : scaled_acc,\n",
    "    'accuracy': cv_result['test_accuracy'].mean(),\n",
    "    'balanced_accuracy': cv_result['test_balanced_accuracy'].mean(),\n",
    "    'f1_weighted': cv_result['test_f1_weighted'].mean(),\n",
    "    'fit_time' : cv_result['fit_time'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = make_pipeline(cv_grid.best_estimator_)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "results_overview['RandomForestClassifier']['Holdout'] = accuracy_score(y_test,clf2.predict(X_test))\n",
    "\n",
    "display(results_overview)\n",
    "\n",
    "# Predict\n",
    "y_prediction = clf.predict(X_res)\n",
    "y_houldout_prediction = clf2.predict(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"RandomTree_amazon_result.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_prediction[i]+'\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(\"RandomTree_amazon_result2.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_houldout_prediction[i]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurs=np.zeros(50)\n",
    "authors=list()\n",
    "\n",
    "for i in range(50):\n",
    "    author=y_prediction[0]\n",
    "    indices=(y_prediction == author)\n",
    "    occurs[i]=np.sum(indices)\n",
    "    authors.append(author)\n",
    "    y_prediction=np.delete(y_prediction,indices)\n",
    "    \n",
    "print(authors)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.bar(authors,occurs)\n",
    "plt.savefig(\"RandomTree_amazon_graphic.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "parameter_grid = {\n",
    "    'n_neighbors': [1,2,3,5,10,15],\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "cv_grid = GridSearchCV(clf, parameter_grid, cv=3, verbose=10, n_jobs=-1, scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], refit='accuracy')\n",
    "cv_grid.fit(X, output_train)\n",
    "\n",
    "print(\"Best Parameter Choice:\")\n",
    "print(cv_grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(cv_grid.best_estimator_)\n",
    "\n",
    "clf.fit(X, output_train)\n",
    "\n",
    "# CV\n",
    "cv_result = cross_validate(clf, X, output_train, cv=3, scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "\n",
    "clf_scaled = make_pipeline(cv_grid.best_estimator_)\n",
    "clf_scaled.fit(X_scale,output_train)\n",
    "scaled_acc = cross_validate(clf_scaled, X_scale, output_train, cv=3, scoring = ['accuracy'], n_jobs=-1)['test_accuracy'].mean()\n",
    "\n",
    "results_overview['NeighborsClassifier'] = {\n",
    "    'scaled accuracy' : scaled_acc,\n",
    "    'accuracy': cv_result['test_accuracy'].mean(),\n",
    "    'balanced_accuracy': cv_result['test_balanced_accuracy'].mean(),\n",
    "    'f1_weighted': cv_result['test_f1_weighted'].mean(),\n",
    "    'fit_time' : cv_result['fit_time'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = make_pipeline(cv_grid.best_estimator_)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "results_overview['NeighborsClassifier']['Holdout'] = accuracy_score(y_test,clf2.predict(X_test))\n",
    "\n",
    "display(results_overview)\n",
    "\n",
    "# Predict\n",
    "y_prediction = clf.predict(X_res)\n",
    "y_houldout_prediction = clf2.predict(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"NeighborsClassifier_amazon_result.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_prediction[i]+'\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(\"NeighborsClassifier_amazon_result2.csv\", \"w\")\n",
    "f.write('ID,\"Class\"\\n')\n",
    "for i in range(750):\n",
    "    f.write(str(i+750)+','+y_houldout_prediction[i]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurs=np.zeros(50)\n",
    "authors=list()\n",
    "\n",
    "for i in range(50):\n",
    "    author=y_prediction[0]\n",
    "    indices=(y_prediction == author)\n",
    "    occurs[i]=np.sum(indices)\n",
    "    authors.append(author)\n",
    "    y_prediction=np.delete(y_prediction,indices)\n",
    "    \n",
    "print(authors)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.bar(authors,occurs)\n",
    "plt.savefig(\"Neigbors_amazon_graphic.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results_overview).T.to_csv(\"Overview_amazon.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
