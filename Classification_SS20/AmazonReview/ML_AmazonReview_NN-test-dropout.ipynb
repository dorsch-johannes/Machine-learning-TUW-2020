{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.23.1.\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.read_csv('./Amazon_Review_Data/amazon_review_ID.shuf.lrn.csv', low_memory=False, sep=',')\n",
    "df_data_test = pd.read_csv('./Amazon_Review_Data/amazon_review_ID.shuf.tes.csv', low_memory=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Davisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wilson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n",
       "0   0   8   6  10   6   7   2   2   2   3  ...      1      0      0      0   \n",
       "1   1  13   1  13   9   8   8   2   3   2  ...      4      1      2      1   \n",
       "2   2  16   7   6   7   9   3   4   2   6  ...      0      0      0      0   \n",
       "3   3   8  11  10  11   3   7   0   4   2  ...      0      0      1      0   \n",
       "4   4  10  11   8   5   3   4   2   5   5  ...      0      0      0      0   \n",
       "\n",
       "   V9996  V9997  V9998  V9999  V10000     Class  \n",
       "0      0      0      0      0       0     Chell  \n",
       "1      0      1      0      0       0  Engineer  \n",
       "2      1      0      0      0       0     Grove  \n",
       "3      0      0      2      1       0  Davisson  \n",
       "4      0      0      0      0       0    Wilson  \n",
       "\n",
       "[5 rows x 10002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "df_data_train['Class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data_train.copy()\n",
    "\n",
    "class_factor = df_data_train['Class'].factorize()\n",
    "class_index = class_factor[1]\n",
    "\n",
    "df_train['ClassF'] = class_factor[0]\n",
    "\n",
    "columns = sorted(set(df_data_train.columns) - set(['ID', 'Class', 'ClassF']))\n",
    "\n",
    "X = df_train[columns].to_numpy()\n",
    "y = df_train['ClassF'].to_numpy()\n",
    "\n",
    "\n",
    "X_test = df_data_test[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDIF Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 10000)\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "unique_classes = np.unique(y)\n",
    "print(len(unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(len(unique_classes), dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  3.9121766090393066  accuracy(train):  0.011666666666666667  accuracy(test):  0.02\n",
      "epoch:  1  loss:  3.8886373043060303  accuracy(train):  0.195  accuracy(test):  0.02\n",
      "epoch:  2  loss:  3.849843740463257  accuracy(train):  0.065  accuracy(test):  0.02666666666666667\n",
      "epoch:  3  loss:  3.815432548522949  accuracy(train):  0.055  accuracy(test):  0.02666666666666667\n",
      "epoch:  4  loss:  3.758972644805908  accuracy(train):  0.06166666666666667  accuracy(test):  0.03333333333333333\n",
      "epoch:  5  loss:  3.6922688484191895  accuracy(train):  0.115  accuracy(test):  0.03333333333333333\n",
      "epoch:  6  loss:  3.614495038986206  accuracy(train):  0.5566666666666666  accuracy(test):  0.05333333333333334\n",
      "epoch:  7  loss:  3.527050733566284  accuracy(train):  0.9433333333333334  accuracy(test):  0.32666666666666666\n",
      "epoch:  8  loss:  3.441265344619751  accuracy(train):  0.9583333333333334  accuracy(test):  0.32666666666666666\n",
      "epoch:  9  loss:  3.361298084259033  accuracy(train):  0.9583333333333334  accuracy(test):  0.24666666666666667\n",
      "epoch:  10  loss:  3.2901175022125244  accuracy(train):  0.9633333333333334  accuracy(test):  0.22666666666666666\n",
      "epoch:  11  loss:  3.2215025424957275  accuracy(train):  0.9783333333333334  accuracy(test):  0.3\n",
      "epoch:  12  loss:  3.1690099239349365  accuracy(train):  0.9916666666666667  accuracy(test):  0.38666666666666666\n",
      "epoch:  13  loss:  3.1198103427886963  accuracy(train):  0.9916666666666667  accuracy(test):  0.42\n",
      "epoch:  14  loss:  3.079923391342163  accuracy(train):  0.9916666666666667  accuracy(test):  0.43333333333333335\n",
      "epoch:  15  loss:  3.048757553100586  accuracy(train):  0.9933333333333333  accuracy(test):  0.38666666666666666\n",
      "epoch:  16  loss:  3.0247156620025635  accuracy(train):  0.9933333333333333  accuracy(test):  0.44\n",
      "epoch:  17  loss:  3.0072104930877686  accuracy(train):  0.9933333333333333  accuracy(test):  0.46\n",
      "epoch:  18  loss:  2.995530128479004  accuracy(train):  0.9933333333333333  accuracy(test):  0.5066666666666667\n",
      "epoch:  19  loss:  2.9830896854400635  accuracy(train):  0.9933333333333333  accuracy(test):  0.5333333333333333\n",
      "epoch:  20  loss:  2.975316286087036  accuracy(train):  0.9933333333333333  accuracy(test):  0.52\n",
      "epoch:  21  loss:  2.9702131748199463  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  22  loss:  2.9667773246765137  accuracy(train):  0.9933333333333333  accuracy(test):  0.5733333333333334\n",
      "epoch:  23  loss:  2.9635305404663086  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  24  loss:  2.960585117340088  accuracy(train):  0.9933333333333333  accuracy(test):  0.5333333333333333\n",
      "epoch:  25  loss:  2.9591894149780273  accuracy(train):  0.9933333333333333  accuracy(test):  0.49333333333333335\n",
      "epoch:  26  loss:  2.9576029777526855  accuracy(train):  0.9933333333333333  accuracy(test):  0.56\n",
      "epoch:  27  loss:  2.9567954540252686  accuracy(train):  0.9933333333333333  accuracy(test):  0.5333333333333333\n",
      "epoch:  28  loss:  2.9561803340911865  accuracy(train):  0.9933333333333333  accuracy(test):  0.5466666666666666\n",
      "epoch:  29  loss:  2.9553279876708984  accuracy(train):  0.9933333333333333  accuracy(test):  0.5533333333333333\n",
      "epoch:  30  loss:  2.955118417739868  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  31  loss:  2.9544641971588135  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  32  loss:  2.954134464263916  accuracy(train):  0.9933333333333333  accuracy(test):  0.5533333333333333\n",
      "epoch:  33  loss:  2.953958034515381  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  34  loss:  2.9537973403930664  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  35  loss:  2.9535107612609863  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  36  loss:  2.9534783363342285  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  37  loss:  2.9532933235168457  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  38  loss:  2.9531445503234863  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  39  loss:  2.9530327320098877  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  40  loss:  2.9530725479125977  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  41  loss:  2.95300555229187  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  42  loss:  2.952934980392456  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  43  loss:  2.9529285430908203  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  44  loss:  2.9528400897979736  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  45  loss:  2.9527957439422607  accuracy(train):  0.9933333333333333  accuracy(test):  0.5733333333333334\n",
      "epoch:  46  loss:  2.9527902603149414  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  47  loss:  2.9527289867401123  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  48  loss:  2.9527182579040527  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  49  loss:  2.9527158737182617  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  50  loss:  2.9526984691619873  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  51  loss:  2.9526755809783936  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  52  loss:  2.952667474746704  accuracy(train):  0.9933333333333333  accuracy(test):  0.58\n",
      "epoch:  53  loss:  2.952644109725952  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  54  loss:  2.9526610374450684  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  55  loss:  2.9526169300079346  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  56  loss:  2.9526045322418213  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  57  loss:  2.952651262283325  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  58  loss:  2.952571153640747  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  59  loss:  2.9525582790374756  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  60  loss:  2.952554941177368  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  61  loss:  2.952556848526001  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  62  loss:  2.9525628089904785  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  63  loss:  2.9525272846221924  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  64  loss:  2.952540159225464  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  65  loss:  2.9525320529937744  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  66  loss:  2.952529191970825  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  67  loss:  2.9525516033172607  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  68  loss:  2.952524185180664  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  69  loss:  2.9525232315063477  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  70  loss:  2.9525206089019775  accuracy(train):  0.9933333333333333  accuracy(test):  0.66\n",
      "epoch:  71  loss:  2.9525094032287598  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  72  loss:  2.952479362487793  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  73  loss:  2.9524972438812256  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  74  loss:  2.9524941444396973  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  75  loss:  2.952486753463745  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  76  loss:  2.9524855613708496  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  77  loss:  2.95249080657959  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  78  loss:  2.952510356903076  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  79  loss:  2.952479362487793  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  80  loss:  2.95247483253479  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  81  loss:  2.952483892440796  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  82  loss:  2.952484130859375  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  83  loss:  2.9524829387664795  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  84  loss:  2.952488899230957  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  85  loss:  2.9525041580200195  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  86  loss:  2.9524857997894287  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  87  loss:  2.9524874687194824  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  88  loss:  2.952465057373047  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  89  loss:  2.9524900913238525  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  90  loss:  2.952455997467041  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  91  loss:  2.952468156814575  accuracy(train):  0.9933333333333333  accuracy(test):  0.6666666666666666\n",
      "epoch:  92  loss:  2.952458143234253  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  93  loss:  2.9524736404418945  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  94  loss:  2.952460527420044  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  95  loss:  2.9524433612823486  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  96  loss:  2.952460765838623  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  97  loss:  2.952446460723877  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  98  loss:  2.9524662494659424  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  99  loss:  2.952439069747925  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  100  loss:  2.9524543285369873  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  101  loss:  2.952441930770874  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  102  loss:  2.952458381652832  accuracy(train):  0.9933333333333333  accuracy(test):  0.5733333333333334\n",
      "epoch:  103  loss:  2.9524481296539307  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  104  loss:  2.952448844909668  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  105  loss:  2.952448844909668  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  106  loss:  2.9524731636047363  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  107  loss:  2.9524362087249756  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  108  loss:  2.9524335861206055  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  109  loss:  2.9524285793304443  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  110  loss:  2.9524550437927246  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  111  loss:  2.952439069747925  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  112  loss:  2.9524428844451904  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  113  loss:  2.952423334121704  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  114  loss:  2.952427864074707  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  115  loss:  2.9524307250976562  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  116  loss:  2.9524343013763428  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  117  loss:  2.9524333477020264  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  118  loss:  2.952418565750122  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  119  loss:  2.952427864074707  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  120  loss:  2.9524238109588623  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  121  loss:  2.9524388313293457  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  122  loss:  2.952413320541382  accuracy(train):  0.9933333333333333  accuracy(test):  0.7066666666666667\n",
      "epoch:  123  loss:  2.952423095703125  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  124  loss:  2.9524378776550293  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  125  loss:  2.952432155609131  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  126  loss:  2.9524285793304443  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  127  loss:  2.952446460723877  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  128  loss:  2.9524292945861816  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  129  loss:  2.9524171352386475  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  130  loss:  2.9524238109588623  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  131  loss:  2.952427387237549  accuracy(train):  0.9933333333333333  accuracy(test):  0.6733333333333333\n",
      "epoch:  132  loss:  2.952427864074707  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  133  loss:  2.95243501663208  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  134  loss:  2.9524147510528564  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  135  loss:  2.952420949935913  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  136  loss:  2.9524097442626953  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  137  loss:  2.952425003051758  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  138  loss:  2.9524292945861816  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  139  loss:  2.95242977142334  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  140  loss:  2.952423572540283  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  141  loss:  2.9524319171905518  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  142  loss:  2.952410936355591  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  143  loss:  2.9524221420288086  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  144  loss:  2.9524097442626953  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  145  loss:  2.9524030685424805  accuracy(train):  0.9933333333333333  accuracy(test):  0.5666666666666667\n",
      "epoch:  146  loss:  2.952399969100952  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  147  loss:  2.952423095703125  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  148  loss:  2.9524011611938477  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  149  loss:  2.9524123668670654  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  150  loss:  2.9524080753326416  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  151  loss:  2.9524006843566895  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  152  loss:  2.9524078369140625  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  153  loss:  2.9524009227752686  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  154  loss:  2.952406406402588  accuracy(train):  0.9933333333333333  accuracy(test):  0.5933333333333334\n",
      "epoch:  155  loss:  2.9524013996124268  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  156  loss:  2.9523935317993164  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  157  loss:  2.9523980617523193  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  158  loss:  2.9523913860321045  accuracy(train):  0.9933333333333333  accuracy(test):  0.6333333333333333\n",
      "epoch:  159  loss:  2.9524011611938477  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  160  loss:  2.952392578125  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  161  loss:  2.952387571334839  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  162  loss:  2.952388048171997  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  163  loss:  2.952394962310791  accuracy(train):  0.9933333333333333  accuracy(test):  0.5866666666666667\n",
      "epoch:  164  loss:  2.952390432357788  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  165  loss:  2.952392339706421  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  166  loss:  2.952394723892212  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  167  loss:  2.952392578125  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  168  loss:  2.9523932933807373  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  169  loss:  2.952390432357788  accuracy(train):  0.9933333333333333  accuracy(test):  0.6666666666666666\n",
      "epoch:  170  loss:  2.9523825645446777  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  171  loss:  2.9523935317993164  accuracy(train):  0.9933333333333333  accuracy(test):  0.58\n",
      "epoch:  172  loss:  2.9523847103118896  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  173  loss:  2.9523894786834717  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  174  loss:  2.9523911476135254  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  175  loss:  2.952392101287842  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  176  loss:  2.952385902404785  accuracy(train):  0.9933333333333333  accuracy(test):  0.6666666666666666\n",
      "epoch:  177  loss:  2.952394723892212  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  178  loss:  2.9523720741271973  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  179  loss:  2.9523894786834717  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  180  loss:  2.952383518218994  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  181  loss:  2.952388048171997  accuracy(train):  0.9933333333333333  accuracy(test):  0.64\n",
      "epoch:  182  loss:  2.952385187149048  accuracy(train):  0.9933333333333333  accuracy(test):  0.6666666666666666\n",
      "epoch:  183  loss:  2.952387809753418  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  184  loss:  2.9523825645446777  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n",
      "epoch:  185  loss:  2.952390670776367  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  186  loss:  2.9523825645446777  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  187  loss:  2.952380895614624  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  188  loss:  2.9523696899414062  accuracy(train):  0.9933333333333333  accuracy(test):  0.68\n",
      "epoch:  189  loss:  2.9523844718933105  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  190  loss:  2.952375888824463  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  191  loss:  2.952373743057251  accuracy(train):  0.9933333333333333  accuracy(test):  0.6\n",
      "epoch:  192  loss:  2.952380418777466  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  193  loss:  2.9523768424987793  accuracy(train):  0.9933333333333333  accuracy(test):  0.6466666666666666\n",
      "epoch:  194  loss:  2.9523754119873047  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  195  loss:  2.9523751735687256  accuracy(train):  0.9933333333333333  accuracy(test):  0.6066666666666667\n",
      "epoch:  196  loss:  2.9523723125457764  accuracy(train):  0.9933333333333333  accuracy(test):  0.6533333333333333\n",
      "epoch:  197  loss:  2.9523777961730957  accuracy(train):  0.9933333333333333  accuracy(test):  0.6266666666666667\n",
      "epoch:  198  loss:  2.952380418777466  accuracy(train):  0.9933333333333333  accuracy(test):  0.62\n",
      "epoch:  199  loss:  2.952373743057251  accuracy(train):  0.9933333333333333  accuracy(test):  0.6133333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  3.9117634296417236  accuracy(train):  0.023333333333333334  accuracy(test):  0.013333333333333334\n",
      "epoch:  1  loss:  3.88700270652771  accuracy(train):  0.11333333333333333  accuracy(test):  0.03333333333333333\n",
      "epoch:  2  loss:  3.848374128341675  accuracy(train):  0.10333333333333333  accuracy(test):  0.02666666666666667\n",
      "epoch:  3  loss:  3.8151321411132812  accuracy(train):  0.08666666666666667  accuracy(test):  0.02666666666666667\n",
      "epoch:  4  loss:  3.76188063621521  accuracy(train):  0.11  accuracy(test):  0.02666666666666667\n",
      "epoch:  5  loss:  3.6944961547851562  accuracy(train):  0.25  accuracy(test):  0.04666666666666667\n",
      "epoch:  6  loss:  3.620084524154663  accuracy(train):  0.7566666666666667  accuracy(test):  0.15333333333333332\n",
      "epoch:  7  loss:  3.5382885932922363  accuracy(train):  0.905  accuracy(test):  0.35333333333333333\n",
      "epoch:  8  loss:  3.455301523208618  accuracy(train):  0.9166666666666666  accuracy(test):  0.34\n",
      "epoch:  9  loss:  3.377531051635742  accuracy(train):  0.9216666666666666  accuracy(test):  0.30666666666666664\n",
      "epoch:  10  loss:  3.3029894828796387  accuracy(train):  0.9516666666666667  accuracy(test):  0.36\n",
      "epoch:  11  loss:  3.238943099975586  accuracy(train):  0.9783333333333334  accuracy(test):  0.38\n",
      "epoch:  12  loss:  3.1832046508789062  accuracy(train):  0.985  accuracy(test):  0.44\n",
      "epoch:  13  loss:  3.1346681118011475  accuracy(train):  0.9883333333333333  accuracy(test):  0.4266666666666667\n",
      "epoch:  14  loss:  3.095057487487793  accuracy(train):  0.9866666666666667  accuracy(test):  0.48\n",
      "epoch:  15  loss:  3.0619473457336426  accuracy(train):  0.9883333333333333  accuracy(test):  0.4266666666666667\n",
      "epoch:  16  loss:  3.03564190864563  accuracy(train):  0.99  accuracy(test):  0.44\n",
      "epoch:  17  loss:  3.017197847366333  accuracy(train):  0.99  accuracy(test):  0.44\n",
      "epoch:  18  loss:  3.00225567817688  accuracy(train):  0.99  accuracy(test):  0.48\n",
      "epoch:  19  loss:  2.990269184112549  accuracy(train):  0.99  accuracy(test):  0.5133333333333333\n",
      "epoch:  20  loss:  2.9814817905426025  accuracy(train):  0.99  accuracy(test):  0.5266666666666666\n",
      "epoch:  21  loss:  2.975391387939453  accuracy(train):  0.99  accuracy(test):  0.4866666666666667\n",
      "epoch:  22  loss:  2.9715425968170166  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  23  loss:  2.9677135944366455  accuracy(train):  0.99  accuracy(test):  0.5333333333333333\n",
      "epoch:  24  loss:  2.965174674987793  accuracy(train):  0.99  accuracy(test):  0.5066666666666667\n",
      "epoch:  25  loss:  2.963184118270874  accuracy(train):  0.99  accuracy(test):  0.52\n",
      "epoch:  26  loss:  2.961469888687134  accuracy(train):  0.99  accuracy(test):  0.5333333333333333\n",
      "epoch:  27  loss:  2.960895538330078  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  28  loss:  2.959750175476074  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  29  loss:  2.959291696548462  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  30  loss:  2.9588406085968018  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  31  loss:  2.9579765796661377  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  32  loss:  2.9576189517974854  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  33  loss:  2.9573745727539062  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  34  loss:  2.9572203159332275  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  35  loss:  2.9570374488830566  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  36  loss:  2.956894636154175  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  37  loss:  2.956709384918213  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  38  loss:  2.956591844558716  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  39  loss:  2.956418037414551  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  40  loss:  2.956364393234253  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  41  loss:  2.9562740325927734  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  42  loss:  2.956285238265991  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  43  loss:  2.956188201904297  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  44  loss:  2.9561173915863037  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  45  loss:  2.9560675621032715  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  46  loss:  2.956040382385254  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  47  loss:  2.955958843231201  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  48  loss:  2.955989360809326  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  49  loss:  2.9559998512268066  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  50  loss:  2.9559223651885986  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  51  loss:  2.9559199810028076  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  52  loss:  2.9559431076049805  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  53  loss:  2.955930233001709  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  54  loss:  2.9558680057525635  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  55  loss:  2.9558486938476562  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  56  loss:  2.955894947052002  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  57  loss:  2.9558448791503906  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  58  loss:  2.9558053016662598  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  59  loss:  2.955822229385376  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  60  loss:  2.9558048248291016  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  61  loss:  2.955836296081543  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  62  loss:  2.9557812213897705  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  63  loss:  2.9557600021362305  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  64  loss:  2.955751895904541  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  65  loss:  2.9557535648345947  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  66  loss:  2.9557809829711914  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  67  loss:  2.9557650089263916  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  68  loss:  2.9557862281799316  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  69  loss:  2.955770969390869  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  70  loss:  2.95576548576355  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  71  loss:  2.9559195041656494  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  72  loss:  2.9557366371154785  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  73  loss:  2.9557485580444336  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  74  loss:  2.9557461738586426  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  75  loss:  2.955747604370117  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  76  loss:  2.955763816833496  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  77  loss:  2.9557673931121826  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  78  loss:  2.9557197093963623  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  79  loss:  2.95573353767395  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  80  loss:  2.955754041671753  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  81  loss:  2.955723762512207  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  82  loss:  2.955714225769043  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  83  loss:  2.955740451812744  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  84  loss:  2.9557015895843506  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  85  loss:  2.9557151794433594  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  86  loss:  2.955739736557007  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  87  loss:  2.955714225769043  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  88  loss:  2.9557108879089355  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  89  loss:  2.955703020095825  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  90  loss:  2.955737829208374  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  91  loss:  2.9557085037231445  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  92  loss:  2.955698013305664  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  93  loss:  2.9556891918182373  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  94  loss:  2.955681085586548  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  95  loss:  2.9556922912597656  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  96  loss:  2.9557249546051025  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  97  loss:  2.955704689025879  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  98  loss:  2.955705165863037  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  99  loss:  2.9556798934936523  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  100  loss:  2.9556803703308105  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  101  loss:  2.955700397491455  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  102  loss:  2.95568585395813  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  103  loss:  2.9556920528411865  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  104  loss:  2.9556820392608643  accuracy(train):  0.99  accuracy(test):  0.6533333333333333\n",
      "epoch:  105  loss:  2.9556703567504883  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  106  loss:  2.955676555633545  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  107  loss:  2.955669403076172  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  108  loss:  2.9556779861450195  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  109  loss:  2.955658435821533  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  110  loss:  2.9556806087493896  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  111  loss:  2.955674409866333  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  112  loss:  2.9556808471679688  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  113  loss:  2.9556589126586914  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  114  loss:  2.9556753635406494  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  115  loss:  2.9556946754455566  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  116  loss:  2.955667495727539  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  117  loss:  2.955667734146118  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  118  loss:  2.9556636810302734  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  119  loss:  2.955650806427002  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  120  loss:  2.955677032470703  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  121  loss:  2.9556503295898438  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  122  loss:  2.9556503295898438  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  123  loss:  2.95564341545105  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  124  loss:  2.955660343170166  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  125  loss:  2.9556686878204346  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  126  loss:  2.955658197402954  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  127  loss:  2.955659866333008  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  128  loss:  2.955646514892578  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  129  loss:  2.9556424617767334  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  130  loss:  2.9556448459625244  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  131  loss:  2.9556493759155273  accuracy(train):  0.99  accuracy(test):  0.6533333333333333\n",
      "epoch:  132  loss:  2.9556891918182373  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  133  loss:  2.955653190612793  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  134  loss:  2.9556498527526855  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  135  loss:  2.955639362335205  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  136  loss:  2.9556381702423096  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  137  loss:  2.955683946609497  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  138  loss:  2.955641984939575  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  139  loss:  2.955636501312256  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  140  loss:  2.955641508102417  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  141  loss:  2.95564341545105  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  142  loss:  2.9556427001953125  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  143  loss:  2.955636501312256  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  144  loss:  2.9556453227996826  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  145  loss:  2.9556338787078857  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  146  loss:  2.95564341545105  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  147  loss:  2.9556331634521484  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  148  loss:  2.955625534057617  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  149  loss:  2.9556493759155273  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  150  loss:  2.9556267261505127  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  151  loss:  2.9556334018707275  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  152  loss:  2.9556312561035156  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  153  loss:  2.955632448196411  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  154  loss:  2.955625534057617  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  155  loss:  2.9556243419647217  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  156  loss:  2.955629348754883  accuracy(train):  0.99  accuracy(test):  0.66\n",
      "epoch:  157  loss:  2.955629587173462  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  158  loss:  2.9556217193603516  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  159  loss:  2.955631732940674  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  160  loss:  2.955636739730835  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  161  loss:  2.955620765686035  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  162  loss:  2.95562744140625  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  163  loss:  2.955629587173462  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  164  loss:  2.955627679824829  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  165  loss:  2.9556174278259277  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  166  loss:  2.955626964569092  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  167  loss:  2.9556193351745605  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  168  loss:  2.9556167125701904  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  169  loss:  2.955625534057617  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  170  loss:  2.955625534057617  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  171  loss:  2.9556336402893066  accuracy(train):  0.99  accuracy(test):  0.66\n",
      "epoch:  172  loss:  2.955627918243408  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  173  loss:  2.955615520477295  accuracy(train):  0.99  accuracy(test):  0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  174  loss:  2.9556124210357666  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  175  loss:  2.955620050430298  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  176  loss:  2.95562744140625  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  177  loss:  2.955608606338501  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  178  loss:  2.955615758895874  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  179  loss:  2.9556069374084473  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  180  loss:  2.955596685409546  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  181  loss:  2.955618381500244  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  182  loss:  2.955615520477295  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  183  loss:  2.9556102752685547  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  184  loss:  2.955599308013916  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  185  loss:  2.9555976390838623  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  186  loss:  2.955599308013916  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  187  loss:  2.955615758895874  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  188  loss:  2.955606698989868  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  189  loss:  2.9556052684783936  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  190  loss:  2.9556095600128174  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  191  loss:  2.955599069595337  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  192  loss:  2.9556055068969727  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  193  loss:  2.955601453781128  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  194  loss:  2.955595016479492  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  195  loss:  2.9556005001068115  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  196  loss:  2.955596685409546  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  197  loss:  2.9556071758270264  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  198  loss:  2.9556164741516113  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  199  loss:  2.9556009769439697  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  3.9120235443115234  accuracy(train):  0.02666666666666667  accuracy(test):  0.02666666666666667\n",
      "epoch:  1  loss:  3.8871257305145264  accuracy(train):  0.1  accuracy(test):  0.04\n",
      "epoch:  2  loss:  3.8451099395751953  accuracy(train):  0.04  accuracy(test):  0.02666666666666667\n",
      "epoch:  3  loss:  3.810004472732544  accuracy(train):  0.03166666666666667  accuracy(test):  0.02\n",
      "epoch:  4  loss:  3.752054452896118  accuracy(train):  0.03  accuracy(test):  0.02\n",
      "epoch:  5  loss:  3.6806466579437256  accuracy(train):  0.06  accuracy(test):  0.02\n",
      "epoch:  6  loss:  3.6023316383361816  accuracy(train):  0.36333333333333334  accuracy(test):  0.08\n",
      "epoch:  7  loss:  3.5175912380218506  accuracy(train):  0.8833333333333333  accuracy(test):  0.24666666666666667\n",
      "epoch:  8  loss:  3.434847831726074  accuracy(train):  0.92  accuracy(test):  0.31333333333333335\n",
      "epoch:  9  loss:  3.3583426475524902  accuracy(train):  0.9216666666666666  accuracy(test):  0.26\n",
      "epoch:  10  loss:  3.290165901184082  accuracy(train):  0.9383333333333334  accuracy(test):  0.26666666666666666\n",
      "epoch:  11  loss:  3.225220203399658  accuracy(train):  0.9566666666666667  accuracy(test):  0.26\n",
      "epoch:  12  loss:  3.174561023712158  accuracy(train):  0.9733333333333334  accuracy(test):  0.4\n",
      "epoch:  13  loss:  3.1256580352783203  accuracy(train):  0.98  accuracy(test):  0.4533333333333333\n",
      "epoch:  14  loss:  3.0856943130493164  accuracy(train):  0.9966666666666667  accuracy(test):  0.3933333333333333\n",
      "epoch:  15  loss:  3.058175563812256  accuracy(train):  0.9983333333333333  accuracy(test):  0.32\n",
      "epoch:  16  loss:  3.029874563217163  accuracy(train):  1.0  accuracy(test):  0.38666666666666666\n",
      "epoch:  17  loss:  3.0099282264709473  accuracy(train):  1.0  accuracy(test):  0.4666666666666667\n",
      "epoch:  18  loss:  2.997282028198242  accuracy(train):  0.9983333333333333  accuracy(test):  0.46\n",
      "epoch:  19  loss:  2.9837284088134766  accuracy(train):  1.0  accuracy(test):  0.47333333333333333\n",
      "epoch:  20  loss:  2.975270986557007  accuracy(train):  1.0  accuracy(test):  0.43333333333333335\n",
      "epoch:  21  loss:  2.968655824661255  accuracy(train):  1.0  accuracy(test):  0.41333333333333333\n",
      "epoch:  22  loss:  2.9642012119293213  accuracy(train):  1.0  accuracy(test):  0.4866666666666667\n",
      "epoch:  23  loss:  2.9589414596557617  accuracy(train):  1.0  accuracy(test):  0.52\n",
      "epoch:  24  loss:  2.95780873298645  accuracy(train):  1.0  accuracy(test):  0.54\n",
      "epoch:  25  loss:  2.9541261196136475  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  26  loss:  2.9522294998168945  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  27  loss:  2.9512362480163574  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  28  loss:  2.950312376022339  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  29  loss:  2.949399948120117  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  30  loss:  2.948873281478882  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  31  loss:  2.948272705078125  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  32  loss:  2.9478349685668945  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  33  loss:  2.9477779865264893  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  34  loss:  2.947439670562744  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  35  loss:  2.947284698486328  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  36  loss:  2.9471304416656494  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  37  loss:  2.94712495803833  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  38  loss:  2.9468021392822266  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  39  loss:  2.946737766265869  accuracy(train):  1.0  accuracy(test):  0.7133333333333334\n",
      "epoch:  40  loss:  2.946701765060425  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  41  loss:  2.946596384048462  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  42  loss:  2.946498394012451  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  43  loss:  2.946420431137085  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  44  loss:  2.9464173316955566  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  45  loss:  2.9463987350463867  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  46  loss:  2.9463391304016113  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  47  loss:  2.9462926387786865  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  48  loss:  2.9463109970092773  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  49  loss:  2.9462778568267822  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  50  loss:  2.946221351623535  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  51  loss:  2.946223258972168  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  52  loss:  2.9462175369262695  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  53  loss:  2.9462080001831055  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  54  loss:  2.9461898803710938  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  55  loss:  2.946164131164551  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  56  loss:  2.9461417198181152  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  57  loss:  2.9461491107940674  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  58  loss:  2.9461746215820312  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  59  loss:  2.946131706237793  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  60  loss:  2.9461193084716797  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  61  loss:  2.946103096008301  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  62  loss:  2.9461169242858887  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  63  loss:  2.946108341217041  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  64  loss:  2.9460883140563965  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  65  loss:  2.9460830688476562  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  66  loss:  2.9460885524749756  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  67  loss:  2.946089029312134  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  68  loss:  2.946073293685913  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  69  loss:  2.9460721015930176  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  70  loss:  2.946066379547119  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  71  loss:  2.9460577964782715  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  72  loss:  2.946049690246582  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  73  loss:  2.9460413455963135  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  74  loss:  2.9460484981536865  accuracy(train):  1.0  accuracy(test):  0.7066666666666667\n",
      "epoch:  75  loss:  2.946047067642212  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  76  loss:  2.9460418224334717  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  77  loss:  2.946038007736206  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  78  loss:  2.9460442066192627  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  79  loss:  2.9460554122924805  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  80  loss:  2.9460580348968506  accuracy(train):  1.0  accuracy(test):  0.7066666666666667\n",
      "epoch:  81  loss:  2.9460365772247314  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  82  loss:  2.946042537689209  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  83  loss:  2.946031093597412  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  84  loss:  2.9460291862487793  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  85  loss:  2.9460456371307373  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  86  loss:  2.945995569229126  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  87  loss:  2.9460208415985107  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  88  loss:  2.9460208415985107  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  89  loss:  2.9460206031799316  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  90  loss:  2.9460372924804688  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  91  loss:  2.946026563644409  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  92  loss:  2.946002960205078  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  93  loss:  2.945997476577759  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  94  loss:  2.946014165878296  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  95  loss:  2.9460067749023438  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  96  loss:  2.9460017681121826  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  97  loss:  2.9460136890411377  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  98  loss:  2.9459967613220215  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  99  loss:  2.9460017681121826  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  100  loss:  2.945981740951538  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  101  loss:  2.94599986076355  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  102  loss:  2.9459848403930664  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  103  loss:  2.9459900856018066  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  104  loss:  2.9460017681121826  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  105  loss:  2.946000337600708  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  106  loss:  2.946009635925293  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  107  loss:  2.9459869861602783  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  108  loss:  2.945988655090332  accuracy(train):  1.0  accuracy(test):  0.7066666666666667\n",
      "epoch:  109  loss:  2.9459915161132812  accuracy(train):  1.0  accuracy(test):  0.72\n",
      "epoch:  110  loss:  2.9459900856018066  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  111  loss:  2.9460155963897705  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  112  loss:  2.9459829330444336  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  113  loss:  2.9459946155548096  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  114  loss:  2.945976495742798  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  115  loss:  2.9459784030914307  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  116  loss:  2.9459779262542725  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  117  loss:  2.946005344390869  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  118  loss:  2.9459822177886963  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  119  loss:  2.945981979370117  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  120  loss:  2.9459948539733887  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  121  loss:  2.94598650932312  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  122  loss:  2.9459879398345947  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  123  loss:  2.945976734161377  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  124  loss:  2.945976734161377  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  125  loss:  2.9459855556488037  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  126  loss:  2.9459762573242188  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  127  loss:  2.945974111557007  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  128  loss:  2.945969343185425  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  129  loss:  2.9459760189056396  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  130  loss:  2.9459707736968994  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  131  loss:  2.945958375930786  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  132  loss:  2.945976734161377  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  133  loss:  2.945953607559204  accuracy(train):  1.0  accuracy(test):  0.72\n",
      "epoch:  134  loss:  2.945974349975586  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  135  loss:  2.9459846019744873  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  136  loss:  2.945965051651001  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  137  loss:  2.945984125137329  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  138  loss:  2.9459683895111084  accuracy(train):  1.0  accuracy(test):  0.7066666666666667\n",
      "epoch:  139  loss:  2.945958137512207  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  140  loss:  2.9459638595581055  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  141  loss:  2.9459621906280518  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  142  loss:  2.945953369140625  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  143  loss:  2.945955514907837  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  144  loss:  2.9459619522094727  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  145  loss:  2.9459593296051025  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  146  loss:  2.945965528488159  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  147  loss:  2.945953845977783  accuracy(train):  1.0  accuracy(test):  0.7066666666666667\n",
      "epoch:  148  loss:  2.9459640979766846  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  149  loss:  2.945950984954834  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  150  loss:  2.945949077606201  accuracy(train):  1.0  accuracy(test):  0.6666666666666666\n",
      "epoch:  151  loss:  2.945953130722046  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  152  loss:  2.9459495544433594  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  153  loss:  2.945955514907837  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  154  loss:  2.94594144821167  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  155  loss:  2.9459476470947266  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  156  loss:  2.9459614753723145  accuracy(train):  1.0  accuracy(test):  0.7266666666666667\n",
      "epoch:  157  loss:  2.9459450244903564  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  158  loss:  2.9459569454193115  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  159  loss:  2.9459517002105713  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  160  loss:  2.94594407081604  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  161  loss:  2.9459521770477295  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  162  loss:  2.9459497928619385  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  163  loss:  2.9459569454193115  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  164  loss:  2.9459452629089355  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  165  loss:  2.94594144821167  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  166  loss:  2.9459471702575684  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  167  loss:  2.9459476470947266  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  168  loss:  2.9459352493286133  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  169  loss:  2.9459400177001953  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  170  loss:  2.9459385871887207  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  171  loss:  2.945943832397461  accuracy(train):  1.0  accuracy(test):  0.7133333333333334\n",
      "epoch:  172  loss:  2.945955276489258  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  173  loss:  2.9459455013275146  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  174  loss:  2.9459354877471924  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  175  loss:  2.945932388305664  accuracy(train):  1.0  accuracy(test):  0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  176  loss:  2.945943593978882  accuracy(train):  1.0  accuracy(test):  0.6933333333333334\n",
      "epoch:  177  loss:  2.9459433555603027  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  178  loss:  2.945932388305664  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  179  loss:  2.9459402561187744  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  180  loss:  2.945953607559204  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  181  loss:  2.9459357261657715  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  182  loss:  2.9459385871887207  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  183  loss:  2.945919990539551  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  184  loss:  2.9459340572357178  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  185  loss:  2.9459354877471924  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  186  loss:  2.945946455001831  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  187  loss:  2.945939779281616  accuracy(train):  1.0  accuracy(test):  0.7\n",
      "epoch:  188  loss:  2.9459261894226074  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  189  loss:  2.945941925048828  accuracy(train):  1.0  accuracy(test):  0.6866666666666666\n",
      "epoch:  190  loss:  2.945925235748291  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  191  loss:  2.9459304809570312  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  192  loss:  2.945931911468506  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  193  loss:  2.9459264278411865  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  194  loss:  2.945934295654297  accuracy(train):  1.0  accuracy(test):  0.66\n",
      "epoch:  195  loss:  2.945924997329712  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  196  loss:  2.9459288120269775  accuracy(train):  1.0  accuracy(test):  0.6733333333333333\n",
      "epoch:  197  loss:  2.945937156677246  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  198  loss:  2.945931911468506  accuracy(train):  1.0  accuracy(test):  0.6533333333333333\n",
      "epoch:  199  loss:  2.945930004119873  accuracy(train):  1.0  accuracy(test):  0.68\n",
      "epoch:  0  loss:  3.9121203422546387  accuracy(train):  0.03166666666666667  accuracy(test):  0.013333333333333334\n",
      "epoch:  1  loss:  3.8860702514648438  accuracy(train):  0.11833333333333333  accuracy(test):  0.04\n",
      "epoch:  2  loss:  3.845228672027588  accuracy(train):  0.15666666666666668  accuracy(test):  0.03333333333333333\n",
      "epoch:  3  loss:  3.8143575191497803  accuracy(train):  0.12833333333333333  accuracy(test):  0.02\n",
      "epoch:  4  loss:  3.765859842300415  accuracy(train):  0.125  accuracy(test):  0.013333333333333334\n",
      "epoch:  5  loss:  3.694204807281494  accuracy(train):  0.19  accuracy(test):  0.006666666666666667\n",
      "epoch:  6  loss:  3.6206274032592773  accuracy(train):  0.7083333333333334  accuracy(test):  0.08666666666666667\n",
      "epoch:  7  loss:  3.539443016052246  accuracy(train):  0.9133333333333333  accuracy(test):  0.3333333333333333\n",
      "epoch:  8  loss:  3.4520161151885986  accuracy(train):  0.9283333333333333  accuracy(test):  0.23333333333333334\n",
      "epoch:  9  loss:  3.3727686405181885  accuracy(train):  0.93  accuracy(test):  0.23333333333333334\n",
      "epoch:  10  loss:  3.29632306098938  accuracy(train):  0.955  accuracy(test):  0.20666666666666667\n",
      "epoch:  11  loss:  3.232090473175049  accuracy(train):  0.975  accuracy(test):  0.26\n",
      "epoch:  12  loss:  3.1765217781066895  accuracy(train):  0.985  accuracy(test):  0.32666666666666666\n",
      "epoch:  13  loss:  3.128028154373169  accuracy(train):  0.9816666666666667  accuracy(test):  0.37333333333333335\n",
      "epoch:  14  loss:  3.0894110202789307  accuracy(train):  0.9833333333333333  accuracy(test):  0.36\n",
      "epoch:  15  loss:  3.059387683868408  accuracy(train):  0.9866666666666667  accuracy(test):  0.3933333333333333\n",
      "epoch:  16  loss:  3.032244920730591  accuracy(train):  0.99  accuracy(test):  0.38666666666666666\n",
      "epoch:  17  loss:  3.014352321624756  accuracy(train):  0.99  accuracy(test):  0.38666666666666666\n",
      "epoch:  18  loss:  2.997709274291992  accuracy(train):  0.99  accuracy(test):  0.43333333333333335\n",
      "epoch:  19  loss:  2.9864795207977295  accuracy(train):  0.99  accuracy(test):  0.4266666666666667\n",
      "epoch:  20  loss:  2.9806416034698486  accuracy(train):  0.99  accuracy(test):  0.44\n",
      "epoch:  21  loss:  2.9738454818725586  accuracy(train):  0.99  accuracy(test):  0.42\n",
      "epoch:  22  loss:  2.969663381576538  accuracy(train):  0.99  accuracy(test):  0.4266666666666667\n",
      "epoch:  23  loss:  2.966574192047119  accuracy(train):  0.99  accuracy(test):  0.5133333333333333\n",
      "epoch:  24  loss:  2.9642441272735596  accuracy(train):  0.99  accuracy(test):  0.49333333333333335\n",
      "epoch:  25  loss:  2.9623916149139404  accuracy(train):  0.99  accuracy(test):  0.4866666666666667\n",
      "epoch:  26  loss:  2.9611475467681885  accuracy(train):  0.99  accuracy(test):  0.5333333333333333\n",
      "epoch:  27  loss:  2.960026741027832  accuracy(train):  0.99  accuracy(test):  0.5133333333333333\n",
      "epoch:  28  loss:  2.9592790603637695  accuracy(train):  0.99  accuracy(test):  0.5333333333333333\n",
      "epoch:  29  loss:  2.9585845470428467  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  30  loss:  2.9581053256988525  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  31  loss:  2.9577057361602783  accuracy(train):  0.99  accuracy(test):  0.5466666666666666\n",
      "epoch:  32  loss:  2.957503318786621  accuracy(train):  0.99  accuracy(test):  0.5466666666666666\n",
      "epoch:  33  loss:  2.9572012424468994  accuracy(train):  0.99  accuracy(test):  0.52\n",
      "epoch:  34  loss:  2.957030773162842  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  35  loss:  2.9568512439727783  accuracy(train):  0.99  accuracy(test):  0.54\n",
      "epoch:  36  loss:  2.956728935241699  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  37  loss:  2.9564616680145264  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  38  loss:  2.9564104080200195  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  39  loss:  2.956399917602539  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  40  loss:  2.956245183944702  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  41  loss:  2.956285238265991  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  42  loss:  2.9561727046966553  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  43  loss:  2.9561071395874023  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  44  loss:  2.956127405166626  accuracy(train):  0.99  accuracy(test):  0.5333333333333333\n",
      "epoch:  45  loss:  2.956042528152466  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  46  loss:  2.955998182296753  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  47  loss:  2.9559521675109863  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  48  loss:  2.9559388160705566  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  49  loss:  2.9559264183044434  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  50  loss:  2.9559290409088135  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  51  loss:  2.9558818340301514  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  52  loss:  2.95588755607605  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  53  loss:  2.9558804035186768  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  54  loss:  2.9558486938476562  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  55  loss:  2.955808162689209  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  56  loss:  2.955824375152588  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  57  loss:  2.9558069705963135  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  58  loss:  2.955808401107788  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  59  loss:  2.9558088779449463  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  60  loss:  2.9557764530181885  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  61  loss:  2.955808162689209  accuracy(train):  0.99  accuracy(test):  0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  62  loss:  2.9557669162750244  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  63  loss:  2.9557337760925293  accuracy(train):  0.99  accuracy(test):  0.5466666666666666\n",
      "epoch:  64  loss:  2.955744504928589  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  65  loss:  2.955744504928589  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  66  loss:  2.9557619094848633  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  67  loss:  2.9557323455810547  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  68  loss:  2.955747127532959  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  69  loss:  2.955735206604004  accuracy(train):  0.99  accuracy(test):  0.54\n",
      "epoch:  70  loss:  2.9557294845581055  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  71  loss:  2.955731153488159  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  72  loss:  2.955717086791992  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  73  loss:  2.955728530883789  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  74  loss:  2.9557297229766846  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  75  loss:  2.955723762512207  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  76  loss:  2.9557082653045654  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  77  loss:  2.9557044506073  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  78  loss:  2.955709934234619  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  79  loss:  2.955716848373413  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  80  loss:  2.955690622329712  accuracy(train):  0.99  accuracy(test):  0.5466666666666666\n",
      "epoch:  81  loss:  2.9556877613067627  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  82  loss:  2.9557104110717773  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  83  loss:  2.955690383911133  accuracy(train):  0.99  accuracy(test):  0.54\n",
      "epoch:  84  loss:  2.955681324005127  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  85  loss:  2.9556961059570312  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  86  loss:  2.95569109916687  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  87  loss:  2.9557008743286133  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  88  loss:  2.9556870460510254  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  89  loss:  2.9556729793548584  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  90  loss:  2.9556760787963867  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  91  loss:  2.9556970596313477  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  92  loss:  2.955686569213867  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  93  loss:  2.9556684494018555  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  94  loss:  2.955697536468506  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  95  loss:  2.9556655883789062  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  96  loss:  2.9556760787963867  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  97  loss:  2.9556632041931152  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  98  loss:  2.9557034969329834  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  99  loss:  2.955681324005127  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  100  loss:  2.9556891918182373  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  101  loss:  2.955679178237915  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  102  loss:  2.955676317214966  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  103  loss:  2.9556753635406494  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  104  loss:  2.955683946609497  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  105  loss:  2.95566463470459  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  106  loss:  2.955660104751587  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  107  loss:  2.9556570053100586  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  108  loss:  2.955671787261963  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  109  loss:  2.955656051635742  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  110  loss:  2.9556636810302734  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  111  loss:  2.9556632041931152  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  112  loss:  2.955655813217163  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  113  loss:  2.9556751251220703  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  114  loss:  2.955658435821533  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  115  loss:  2.9556567668914795  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  116  loss:  2.9556591510772705  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  117  loss:  2.955648422241211  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  118  loss:  2.9556477069854736  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  119  loss:  2.9556593894958496  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  120  loss:  2.9556424617767334  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  121  loss:  2.955643653869629  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  122  loss:  2.955655097961426  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  123  loss:  2.9556310176849365  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  124  loss:  2.955655813217163  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  125  loss:  2.95564866065979  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  126  loss:  2.955657482147217  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  127  loss:  2.9556472301483154  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  128  loss:  2.9556331634521484  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  129  loss:  2.955636501312256  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  130  loss:  2.9556405544281006  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  131  loss:  2.9556379318237305  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  132  loss:  2.9556539058685303  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  133  loss:  2.9556379318237305  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  134  loss:  2.955646514892578  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  135  loss:  2.955634832382202  accuracy(train):  0.99  accuracy(test):  0.54\n",
      "epoch:  136  loss:  2.9556281566619873  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  137  loss:  2.9556264877319336  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  138  loss:  2.9556243419647217  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  139  loss:  2.9556217193603516  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  140  loss:  2.955623149871826  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  141  loss:  2.9556291103363037  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  142  loss:  2.9556360244750977  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  143  loss:  2.9556264877319336  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  144  loss:  2.9556214809417725  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  145  loss:  2.9556286334991455  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  146  loss:  2.9556262493133545  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  147  loss:  2.9556267261505127  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  148  loss:  2.955622673034668  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  149  loss:  2.9556214809417725  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  150  loss:  2.9556143283843994  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  151  loss:  2.955613613128662  accuracy(train):  0.99  accuracy(test):  0.6333333333333333\n",
      "epoch:  152  loss:  2.955608606338501  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  153  loss:  2.9556117057800293  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  154  loss:  2.955612897872925  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  155  loss:  2.955605983734131  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  156  loss:  2.955613136291504  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  157  loss:  2.955613851547241  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  158  loss:  2.9556169509887695  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  159  loss:  2.9556100368499756  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  160  loss:  2.9556190967559814  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  161  loss:  2.9556076526641846  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  162  loss:  2.955612897872925  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  163  loss:  2.9556167125701904  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  164  loss:  2.9556093215942383  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  165  loss:  2.9555981159210205  accuracy(train):  0.99  accuracy(test):  0.6066666666666667\n",
      "epoch:  166  loss:  2.9556055068969727  accuracy(train):  0.99  accuracy(test):  0.64\n",
      "epoch:  167  loss:  2.955604076385498  accuracy(train):  0.99  accuracy(test):  0.5733333333333334\n",
      "epoch:  168  loss:  2.9556045532226562  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  169  loss:  2.9556097984313965  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  170  loss:  2.955604314804077  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  171  loss:  2.9556078910827637  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  172  loss:  2.9556028842926025  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  173  loss:  2.955605983734131  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  174  loss:  2.9555978775024414  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  175  loss:  2.95561146736145  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  176  loss:  2.9556050300598145  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  177  loss:  2.9555962085723877  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  178  loss:  2.9555959701538086  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  179  loss:  2.955592155456543  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  180  loss:  2.955599784851074  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  181  loss:  2.955597400665283  accuracy(train):  0.99  accuracy(test):  0.56\n",
      "epoch:  182  loss:  2.9556055068969727  accuracy(train):  0.99  accuracy(test):  0.5666666666666667\n",
      "epoch:  183  loss:  2.9555931091308594  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  184  loss:  2.955599308013916  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  185  loss:  2.955599069595337  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  186  loss:  2.9555952548980713  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  187  loss:  2.9555866718292236  accuracy(train):  0.99  accuracy(test):  0.5533333333333333\n",
      "epoch:  188  loss:  2.9555962085723877  accuracy(train):  0.99  accuracy(test):  0.6266666666666667\n",
      "epoch:  189  loss:  2.9556005001068115  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  190  loss:  2.9555933475494385  accuracy(train):  0.99  accuracy(test):  0.62\n",
      "epoch:  191  loss:  2.955592393875122  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  192  loss:  2.955599784851074  accuracy(train):  0.99  accuracy(test):  0.58\n",
      "epoch:  193  loss:  2.955594062805176  accuracy(train):  0.99  accuracy(test):  0.6466666666666666\n",
      "epoch:  194  loss:  2.9555935859680176  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  195  loss:  2.955585241317749  accuracy(train):  0.99  accuracy(test):  0.5866666666666667\n",
      "epoch:  196  loss:  2.9555840492248535  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n",
      "epoch:  197  loss:  2.955592155456543  accuracy(train):  0.99  accuracy(test):  0.6\n",
      "epoch:  198  loss:  2.9555881023406982  accuracy(train):  0.99  accuracy(test):  0.5933333333333334\n",
      "epoch:  199  loss:  2.9555962085723877  accuracy(train):  0.99  accuracy(test):  0.6133333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  3.9119796752929688  accuracy(train):  0.008333333333333333  accuracy(test):  0.013333333333333334\n",
      "epoch:  1  loss:  3.887962579727173  accuracy(train):  0.03333333333333333  accuracy(test):  0.013333333333333334\n",
      "epoch:  2  loss:  3.850940465927124  accuracy(train):  0.03166666666666667  accuracy(test):  0.013333333333333334\n",
      "epoch:  3  loss:  3.816729784011841  accuracy(train):  0.03166666666666667  accuracy(test):  0.013333333333333334\n",
      "epoch:  4  loss:  3.7655558586120605  accuracy(train):  0.03333333333333333  accuracy(test):  0.013333333333333334\n",
      "epoch:  5  loss:  3.6984355449676514  accuracy(train):  0.03666666666666667  accuracy(test):  0.013333333333333334\n",
      "epoch:  6  loss:  3.6268839836120605  accuracy(train):  0.13833333333333334  accuracy(test):  0.02666666666666667\n",
      "epoch:  7  loss:  3.5455565452575684  accuracy(train):  0.6566666666666666  accuracy(test):  0.12666666666666668\n",
      "epoch:  8  loss:  3.4593582153320312  accuracy(train):  0.9366666666666666  accuracy(test):  0.3\n",
      "epoch:  9  loss:  3.3787829875946045  accuracy(train):  0.9466666666666667  accuracy(test):  0.29333333333333333\n",
      "epoch:  10  loss:  3.2999212741851807  accuracy(train):  0.965  accuracy(test):  0.24666666666666667\n",
      "epoch:  11  loss:  3.2372028827667236  accuracy(train):  0.9866666666666667  accuracy(test):  0.24\n",
      "epoch:  12  loss:  3.1817381381988525  accuracy(train):  0.995  accuracy(test):  0.26\n",
      "epoch:  13  loss:  3.12958025932312  accuracy(train):  1.0  accuracy(test):  0.3466666666666667\n",
      "epoch:  14  loss:  3.08905291557312  accuracy(train):  0.9983333333333333  accuracy(test):  0.3933333333333333\n",
      "epoch:  15  loss:  3.055859088897705  accuracy(train):  1.0  accuracy(test):  0.38666666666666666\n",
      "epoch:  16  loss:  3.029348850250244  accuracy(train):  1.0  accuracy(test):  0.38\n",
      "epoch:  17  loss:  3.0078892707824707  accuracy(train):  1.0  accuracy(test):  0.36666666666666664\n",
      "epoch:  18  loss:  2.9930951595306396  accuracy(train):  1.0  accuracy(test):  0.4533333333333333\n",
      "epoch:  19  loss:  2.98237943649292  accuracy(train):  1.0  accuracy(test):  0.44\n",
      "epoch:  20  loss:  2.9734115600585938  accuracy(train):  1.0  accuracy(test):  0.44666666666666666\n",
      "epoch:  21  loss:  2.967660903930664  accuracy(train):  1.0  accuracy(test):  0.5\n",
      "epoch:  22  loss:  2.9624643325805664  accuracy(train):  1.0  accuracy(test):  0.47333333333333333\n",
      "epoch:  23  loss:  2.958723306655884  accuracy(train):  1.0  accuracy(test):  0.5\n",
      "epoch:  24  loss:  2.955850124359131  accuracy(train):  1.0  accuracy(test):  0.4666666666666667\n",
      "epoch:  25  loss:  2.9537744522094727  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  26  loss:  2.952256917953491  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  27  loss:  2.9510881900787354  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  28  loss:  2.950434923171997  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  29  loss:  2.9495463371276855  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  30  loss:  2.948925495147705  accuracy(train):  1.0  accuracy(test):  0.54\n",
      "epoch:  31  loss:  2.9484176635742188  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  32  loss:  2.9481043815612793  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  33  loss:  2.947845935821533  accuracy(train):  1.0  accuracy(test):  0.5333333333333333\n",
      "epoch:  34  loss:  2.94756817817688  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  35  loss:  2.9472312927246094  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  36  loss:  2.9471993446350098  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  37  loss:  2.9470362663269043  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  38  loss:  2.9469494819641113  accuracy(train):  1.0  accuracy(test):  0.5533333333333333\n",
      "epoch:  39  loss:  2.946829080581665  accuracy(train):  1.0  accuracy(test):  0.5533333333333333\n",
      "epoch:  40  loss:  2.9466934204101562  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  41  loss:  2.9466142654418945  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  42  loss:  2.9466726779937744  accuracy(train):  1.0  accuracy(test):  0.52\n",
      "epoch:  43  loss:  2.946542978286743  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  44  loss:  2.9464924335479736  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  45  loss:  2.9463744163513184  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  46  loss:  2.946380853652954  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  47  loss:  2.9464266300201416  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  48  loss:  2.946321487426758  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  49  loss:  2.9463186264038086  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  50  loss:  2.946277141571045  accuracy(train):  1.0  accuracy(test):  0.5333333333333333\n",
      "epoch:  51  loss:  2.9462523460388184  accuracy(train):  1.0  accuracy(test):  0.6333333333333333\n",
      "epoch:  52  loss:  2.946272134780884  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  53  loss:  2.9462850093841553  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  54  loss:  2.9462342262268066  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  55  loss:  2.9461894035339355  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  56  loss:  2.946207046508789  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  57  loss:  2.9461870193481445  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  58  loss:  2.946183204650879  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  59  loss:  2.9462053775787354  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  60  loss:  2.946216344833374  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  61  loss:  2.946150064468384  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  62  loss:  2.946169376373291  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  63  loss:  2.9461653232574463  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  64  loss:  2.9461498260498047  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  65  loss:  2.946136474609375  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  66  loss:  2.9461076259613037  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  67  loss:  2.9461135864257812  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  68  loss:  2.9461162090301514  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  69  loss:  2.946133613586426  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  70  loss:  2.9460997581481934  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  71  loss:  2.946077585220337  accuracy(train):  1.0  accuracy(test):  0.5333333333333333\n",
      "epoch:  72  loss:  2.946105480194092  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  73  loss:  2.946091413497925  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  74  loss:  2.9460954666137695  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  75  loss:  2.9460678100585938  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  76  loss:  2.9460859298706055  accuracy(train):  1.0  accuracy(test):  0.5333333333333333\n",
      "epoch:  77  loss:  2.9460880756378174  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  78  loss:  2.9460790157318115  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  79  loss:  2.9460906982421875  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  80  loss:  2.9460761547088623  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  81  loss:  2.9460649490356445  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  82  loss:  2.9460504055023193  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  83  loss:  2.946061134338379  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  84  loss:  2.9460558891296387  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  85  loss:  2.9460628032684326  accuracy(train):  1.0  accuracy(test):  0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  86  loss:  2.946068286895752  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  87  loss:  2.946080207824707  accuracy(train):  1.0  accuracy(test):  0.5533333333333333\n",
      "epoch:  88  loss:  2.946052074432373  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  89  loss:  2.946049451828003  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  90  loss:  2.946059226989746  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  91  loss:  2.946053981781006  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  92  loss:  2.9460580348968506  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  93  loss:  2.946042537689209  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  94  loss:  2.9460456371307373  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  95  loss:  2.946038007736206  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  96  loss:  2.9460458755493164  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  97  loss:  2.9460341930389404  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  98  loss:  2.9460556507110596  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  99  loss:  2.9460434913635254  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  100  loss:  2.946051836013794  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  101  loss:  2.9460461139678955  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  102  loss:  2.946028470993042  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  103  loss:  2.9460268020629883  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  104  loss:  2.946026563644409  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  105  loss:  2.946023464202881  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  106  loss:  2.946017026901245  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  107  loss:  2.946026086807251  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  108  loss:  2.9460248947143555  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  109  loss:  2.9460206031799316  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  110  loss:  2.9460179805755615  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  111  loss:  2.9460256099700928  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  112  loss:  2.9460160732269287  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  113  loss:  2.946035146713257  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  114  loss:  2.9460108280181885  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  115  loss:  2.946012258529663  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  116  loss:  2.9460127353668213  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  117  loss:  2.9460220336914062  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  118  loss:  2.9460062980651855  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  119  loss:  2.946011543273926  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  120  loss:  2.94600772857666  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  121  loss:  2.9460034370422363  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  122  loss:  2.9460067749023438  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  123  loss:  2.945992946624756  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  124  loss:  2.9460132122039795  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  125  loss:  2.9459969997406006  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  126  loss:  2.94602108001709  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  127  loss:  2.9460103511810303  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  128  loss:  2.945985794067383  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  129  loss:  2.9459991455078125  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  130  loss:  2.945985794067383  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  131  loss:  2.9460020065307617  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  132  loss:  2.945997476577759  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  133  loss:  2.9459965229034424  accuracy(train):  1.0  accuracy(test):  0.52\n",
      "epoch:  134  loss:  2.945981979370117  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  135  loss:  2.9460015296936035  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  136  loss:  2.945979595184326  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  137  loss:  2.9459943771362305  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  138  loss:  2.945993185043335  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  139  loss:  2.9459874629974365  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  140  loss:  2.9459943771362305  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  141  loss:  2.945990800857544  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  142  loss:  2.9459917545318604  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  143  loss:  2.9459755420684814  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  144  loss:  2.9459664821624756  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  145  loss:  2.945991039276123  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  146  loss:  2.9459893703460693  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  147  loss:  2.945979118347168  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  148  loss:  2.945979356765747  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  149  loss:  2.9459707736968994  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  150  loss:  2.9459707736968994  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  151  loss:  2.945974349975586  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  152  loss:  2.945988655090332  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  153  loss:  2.945974588394165  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  154  loss:  2.945978879928589  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  155  loss:  2.9459691047668457  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  156  loss:  2.945970058441162  accuracy(train):  1.0  accuracy(test):  0.56\n",
      "epoch:  157  loss:  2.945957899093628  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  158  loss:  2.945974349975586  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  159  loss:  2.945979118347168  accuracy(train):  1.0  accuracy(test):  0.5266666666666666\n",
      "epoch:  160  loss:  2.945967197418213  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  161  loss:  2.945967197418213  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  162  loss:  2.9459595680236816  accuracy(train):  1.0  accuracy(test):  0.5533333333333333\n",
      "epoch:  163  loss:  2.945953130722046  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  164  loss:  2.9459574222564697  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  165  loss:  2.945958375930786  accuracy(train):  1.0  accuracy(test):  0.54\n",
      "epoch:  166  loss:  2.9459691047668457  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  167  loss:  2.9459574222564697  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  168  loss:  2.945962429046631  accuracy(train):  1.0  accuracy(test):  0.5533333333333333\n",
      "epoch:  169  loss:  2.9459588527679443  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  170  loss:  2.945976972579956  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  171  loss:  2.945970296859741  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  172  loss:  2.9459588527679443  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  173  loss:  2.945971727371216  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  174  loss:  2.9459662437438965  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  175  loss:  2.9459686279296875  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  176  loss:  2.945948600769043  accuracy(train):  1.0  accuracy(test):  0.62\n",
      "epoch:  177  loss:  2.945955991744995  accuracy(train):  1.0  accuracy(test):  0.6266666666666667\n",
      "epoch:  178  loss:  2.945949077606201  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  179  loss:  2.945955514907837  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  180  loss:  2.9459645748138428  accuracy(train):  1.0  accuracy(test):  0.5466666666666666\n",
      "epoch:  181  loss:  2.945974588394165  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  182  loss:  2.9459478855133057  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  183  loss:  2.9459612369537354  accuracy(train):  1.0  accuracy(test):  0.5733333333333334\n",
      "epoch:  184  loss:  2.9459595680236816  accuracy(train):  1.0  accuracy(test):  0.6466666666666666\n",
      "epoch:  185  loss:  2.945950746536255  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  186  loss:  2.945960760116577  accuracy(train):  1.0  accuracy(test):  0.6133333333333333\n",
      "epoch:  187  loss:  2.9459445476531982  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  188  loss:  2.9459471702575684  accuracy(train):  1.0  accuracy(test):  0.5666666666666667\n",
      "epoch:  189  loss:  2.9459478855133057  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  190  loss:  2.9459385871887207  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  191  loss:  2.945952892303467  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "epoch:  192  loss:  2.945950508117676  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  193  loss:  2.945951461791992  accuracy(train):  1.0  accuracy(test):  0.58\n",
      "epoch:  194  loss:  2.9459400177001953  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  195  loss:  2.945955514907837  accuracy(train):  1.0  accuracy(test):  0.6066666666666667\n",
      "epoch:  196  loss:  2.9459431171417236  accuracy(train):  1.0  accuracy(test):  0.5933333333333334\n",
      "epoch:  197  loss:  2.945941686630249  accuracy(train):  1.0  accuracy(test):  0.64\n",
      "epoch:  198  loss:  2.945934534072876  accuracy(train):  1.0  accuracy(test):  0.5866666666666667\n",
      "epoch:  199  loss:  2.9459388256073  accuracy(train):  1.0  accuracy(test):  0.6\n",
      "{'Type': 'MLP', 'accuracy': 0.6199999999999999, 'accuracy_sd': 0.04066120181860507, 'balanced_accuracy': 0.646875643283318, 'balanced_accuracy_sd': 0.04022053952540245, 'f1_weighted': 0.6079392533392534, 'f1_weighted_sd': 0.034533009257673546}\n",
      "time: 348.73827385902405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "def create_model():\n",
    "    num_inputs = 10000\n",
    "    num_outputs = 50\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(num_inputs, 1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1000, num_outputs),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "def nn_fit_and_predict(X_cv_train, y_cv_train, X_cv_test, y_cv_test):\n",
    "    nX = torch.from_numpy(X_cv_train.todense()).float()\n",
    "    nX_test = torch.from_numpy(X_cv_test.todense()).float()\n",
    "    ny = torch.from_numpy(y_cv_train)\n",
    "    ny_test = torch.from_numpy(y_cv_test)\n",
    "\n",
    "    # Train network\n",
    "    model = create_model()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "    for epoch in range(200):\n",
    "        y_pred = model(nX)\n",
    "\n",
    "        loss = criterion(y_pred, ny)\n",
    "\n",
    "        y_pred_a = torch.argmax(y_pred, dim=1).detach().numpy()\n",
    "        accuracy = accuracy_score(y_pred_a, ny)\n",
    "        \n",
    "        y_pred_test = model(nX_test)\n",
    "        y_pred_a_test = torch.argmax(y_pred_test, dim=1).detach().numpy()\n",
    "        accuracy_test = accuracy_score(y_pred_a_test, ny_test)\n",
    "\n",
    "        print('epoch: ', epoch,' loss: ', loss.item(),' accuracy(train): ', accuracy,' accuracy(test): ', accuracy_test)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    # Finally predict test\n",
    "    y_output = model(nX_test)\n",
    "    y_prediction = torch.argmax(y_output, dim=1).detach().numpy()\n",
    "    return y_prediction\n",
    "\n",
    "\n",
    "cv_results_accuracy = []\n",
    "cv_results_balanced_accuracy = []\n",
    "cv_results_f1_weighted = []\n",
    "    \n",
    "cv_fold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for train_index, test_index in cv_fold.split(X):\n",
    "    X_cv_train = X_tfidf[train_index,:]\n",
    "    X_cv_test = X_tfidf[test_index,:]\n",
    "    \n",
    "    y_cv_train = y[train_index]\n",
    "    y_cv_test = y[test_index]\n",
    "    \n",
    "    y_cv_test_pred = nn_fit_and_predict(X_cv_train, y_cv_train, X_cv_test, y_cv_test)\n",
    "    \n",
    "    cv_results_accuracy.append(accuracy_score(y_cv_test, y_cv_test_pred))\n",
    "    cv_results_balanced_accuracy.append(balanced_accuracy_score(y_cv_test, y_cv_test_pred))\n",
    "    cv_results_f1_weighted.append(f1_score(y_cv_test, y_cv_test_pred, average='weighted'))\n",
    "    \n",
    "time_end = time.time()\n",
    "    \n",
    "cv_results = {\n",
    "    'Type': 'MLP',\n",
    "    'accuracy': np.array(cv_results_accuracy).mean(),\n",
    "    'accuracy_sd': np.std(np.array(cv_results_accuracy)),\n",
    "    'balanced_accuracy': np.array(cv_results_balanced_accuracy).mean(),\n",
    "    'balanced_accuracy_sd': np.std(np.array(cv_results_balanced_accuracy)),\n",
    "    'f1_weighted': np.array(cv_results_f1_weighted).mean(),\n",
    "    'f1_weighted_sd': np.std(np.array(cv_results_f1_weighted)),\n",
    "}\n",
    "print(cv_results)\n",
    "print('time: %s' % (time_end - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  3.9119296073913574  accuracy:  0.016\n",
      "epoch:  1  loss:  3.894451379776001  accuracy:  0.08666666666666667\n",
      "epoch:  2  loss:  3.8648056983947754  accuracy:  0.08533333333333333\n",
      "epoch:  3  loss:  3.8358750343322754  accuracy:  0.052\n",
      "epoch:  4  loss:  3.7978479862213135  accuracy:  0.05466666666666667\n",
      "epoch:  5  loss:  3.7504520416259766  accuracy:  0.09066666666666667\n",
      "epoch:  6  loss:  3.684314012527466  accuracy:  0.33866666666666667\n",
      "epoch:  7  loss:  3.6230928897857666  accuracy:  0.7266666666666667\n",
      "epoch:  8  loss:  3.549659490585327  accuracy:  0.8413333333333334\n",
      "epoch:  9  loss:  3.4757132530212402  accuracy:  0.872\n",
      "epoch:  10  loss:  3.4141016006469727  accuracy:  0.864\n",
      "epoch:  11  loss:  3.3538095951080322  accuracy:  0.8706666666666667\n",
      "epoch:  12  loss:  3.29276442527771  accuracy:  0.912\n",
      "epoch:  13  loss:  3.251150131225586  accuracy:  0.9293333333333333\n",
      "epoch:  14  loss:  3.2006676197052  accuracy:  0.9573333333333334\n",
      "epoch:  15  loss:  3.1646506786346436  accuracy:  0.9626666666666667\n",
      "epoch:  16  loss:  3.124422550201416  accuracy:  0.9773333333333334\n",
      "epoch:  17  loss:  3.096989631652832  accuracy:  0.9773333333333334\n",
      "epoch:  18  loss:  3.0729050636291504  accuracy:  0.9813333333333333\n",
      "epoch:  19  loss:  3.053340435028076  accuracy:  0.984\n",
      "epoch:  20  loss:  3.0346169471740723  accuracy:  0.9866666666666667\n",
      "epoch:  21  loss:  3.021038770675659  accuracy:  0.9893333333333333\n",
      "epoch:  22  loss:  3.0083603858947754  accuracy:  0.9893333333333333\n",
      "epoch:  23  loss:  2.999675750732422  accuracy:  0.9893333333333333\n",
      "epoch:  24  loss:  2.991811752319336  accuracy:  0.9906666666666667\n",
      "epoch:  25  loss:  2.9863176345825195  accuracy:  0.9893333333333333\n",
      "epoch:  26  loss:  2.979315996170044  accuracy:  0.9933333333333333\n",
      "epoch:  27  loss:  2.9768826961517334  accuracy:  0.9986666666666667\n",
      "epoch:  28  loss:  2.9715359210968018  accuracy:  1.0\n",
      "epoch:  29  loss:  2.970000982284546  accuracy:  1.0\n",
      "epoch:  30  loss:  2.9675071239471436  accuracy:  1.0\n",
      "epoch:  31  loss:  2.9641530513763428  accuracy:  1.0\n",
      "epoch:  32  loss:  2.9623045921325684  accuracy:  0.9986666666666667\n",
      "epoch:  33  loss:  2.960097551345825  accuracy:  0.9986666666666667\n",
      "epoch:  34  loss:  2.9586966037750244  accuracy:  1.0\n",
      "epoch:  35  loss:  2.956879138946533  accuracy:  1.0\n",
      "epoch:  36  loss:  2.9550347328186035  accuracy:  1.0\n",
      "epoch:  37  loss:  2.9541382789611816  accuracy:  1.0\n",
      "epoch:  38  loss:  2.9535436630249023  accuracy:  1.0\n",
      "epoch:  39  loss:  2.952197551727295  accuracy:  1.0\n",
      "epoch:  40  loss:  2.9515531063079834  accuracy:  1.0\n",
      "epoch:  41  loss:  2.9507930278778076  accuracy:  1.0\n",
      "epoch:  42  loss:  2.9506919384002686  accuracy:  1.0\n",
      "epoch:  43  loss:  2.9502639770507812  accuracy:  1.0\n",
      "epoch:  44  loss:  2.949613332748413  accuracy:  1.0\n",
      "epoch:  45  loss:  2.949366569519043  accuracy:  1.0\n",
      "epoch:  46  loss:  2.9493489265441895  accuracy:  1.0\n",
      "epoch:  47  loss:  2.9487240314483643  accuracy:  1.0\n",
      "epoch:  48  loss:  2.948404312133789  accuracy:  1.0\n",
      "epoch:  49  loss:  2.9485185146331787  accuracy:  1.0\n",
      "epoch:  50  loss:  2.9481360912323  accuracy:  1.0\n",
      "epoch:  51  loss:  2.947996139526367  accuracy:  1.0\n",
      "epoch:  52  loss:  2.94808292388916  accuracy:  1.0\n",
      "epoch:  53  loss:  2.9479258060455322  accuracy:  1.0\n",
      "epoch:  54  loss:  2.947969436645508  accuracy:  1.0\n",
      "epoch:  55  loss:  2.947711944580078  accuracy:  1.0\n",
      "epoch:  56  loss:  2.947855234146118  accuracy:  1.0\n",
      "epoch:  57  loss:  2.947798490524292  accuracy:  1.0\n",
      "epoch:  58  loss:  2.9474732875823975  accuracy:  1.0\n",
      "epoch:  59  loss:  2.94765043258667  accuracy:  1.0\n",
      "epoch:  60  loss:  2.9473538398742676  accuracy:  1.0\n",
      "epoch:  61  loss:  2.9473490715026855  accuracy:  1.0\n",
      "epoch:  62  loss:  2.947495460510254  accuracy:  1.0\n",
      "epoch:  63  loss:  2.9472649097442627  accuracy:  1.0\n",
      "epoch:  64  loss:  2.9475064277648926  accuracy:  1.0\n",
      "epoch:  65  loss:  2.947108507156372  accuracy:  1.0\n",
      "epoch:  66  loss:  2.947171926498413  accuracy:  1.0\n",
      "epoch:  67  loss:  2.947087526321411  accuracy:  1.0\n",
      "epoch:  68  loss:  2.9471988677978516  accuracy:  1.0\n",
      "epoch:  69  loss:  2.947235345840454  accuracy:  1.0\n",
      "epoch:  70  loss:  2.9470622539520264  accuracy:  1.0\n",
      "epoch:  71  loss:  2.9472262859344482  accuracy:  1.0\n",
      "epoch:  72  loss:  2.947082996368408  accuracy:  1.0\n",
      "epoch:  73  loss:  2.947019577026367  accuracy:  1.0\n",
      "epoch:  74  loss:  2.947080135345459  accuracy:  1.0\n",
      "epoch:  75  loss:  2.9470202922821045  accuracy:  1.0\n",
      "epoch:  76  loss:  2.9470155239105225  accuracy:  1.0\n",
      "epoch:  77  loss:  2.946939468383789  accuracy:  1.0\n",
      "epoch:  78  loss:  2.9470276832580566  accuracy:  1.0\n",
      "epoch:  79  loss:  2.946962833404541  accuracy:  1.0\n",
      "epoch:  80  loss:  2.9469797611236572  accuracy:  1.0\n",
      "epoch:  81  loss:  2.9468398094177246  accuracy:  1.0\n",
      "epoch:  82  loss:  2.946911573410034  accuracy:  1.0\n",
      "epoch:  83  loss:  2.946974039077759  accuracy:  1.0\n",
      "epoch:  84  loss:  2.9468719959259033  accuracy:  1.0\n",
      "epoch:  85  loss:  2.946864366531372  accuracy:  1.0\n",
      "epoch:  86  loss:  2.946742534637451  accuracy:  1.0\n",
      "epoch:  87  loss:  2.946840286254883  accuracy:  1.0\n",
      "epoch:  88  loss:  2.94681453704834  accuracy:  1.0\n",
      "epoch:  89  loss:  2.9469289779663086  accuracy:  1.0\n",
      "epoch:  90  loss:  2.9467990398406982  accuracy:  1.0\n",
      "epoch:  91  loss:  2.946730852127075  accuracy:  1.0\n",
      "epoch:  92  loss:  2.9467978477478027  accuracy:  1.0\n",
      "epoch:  93  loss:  2.946721076965332  accuracy:  1.0\n",
      "epoch:  94  loss:  2.9467012882232666  accuracy:  1.0\n",
      "epoch:  95  loss:  2.946704149246216  accuracy:  1.0\n",
      "epoch:  96  loss:  2.946660041809082  accuracy:  1.0\n",
      "epoch:  97  loss:  2.9466795921325684  accuracy:  1.0\n",
      "epoch:  98  loss:  2.946711301803589  accuracy:  1.0\n",
      "epoch:  99  loss:  2.9466712474823  accuracy:  1.0\n",
      "epoch:  100  loss:  2.946671485900879  accuracy:  1.0\n",
      "epoch:  101  loss:  2.946582794189453  accuracy:  1.0\n",
      "epoch:  102  loss:  2.9465792179107666  accuracy:  1.0\n",
      "epoch:  103  loss:  2.9466118812561035  accuracy:  1.0\n",
      "epoch:  104  loss:  2.9466359615325928  accuracy:  1.0\n",
      "epoch:  105  loss:  2.9466865062713623  accuracy:  1.0\n",
      "epoch:  106  loss:  2.9466543197631836  accuracy:  1.0\n",
      "epoch:  107  loss:  2.94663405418396  accuracy:  1.0\n",
      "epoch:  108  loss:  2.9466238021850586  accuracy:  1.0\n",
      "epoch:  109  loss:  2.946657657623291  accuracy:  1.0\n",
      "epoch:  110  loss:  2.946526288986206  accuracy:  1.0\n",
      "epoch:  111  loss:  2.9465785026550293  accuracy:  1.0\n",
      "epoch:  112  loss:  2.946549415588379  accuracy:  1.0\n",
      "epoch:  113  loss:  2.9465138912200928  accuracy:  1.0\n",
      "epoch:  114  loss:  2.9465525150299072  accuracy:  1.0\n",
      "epoch:  115  loss:  2.9465439319610596  accuracy:  1.0\n",
      "epoch:  116  loss:  2.94651460647583  accuracy:  1.0\n",
      "epoch:  117  loss:  2.9465651512145996  accuracy:  1.0\n",
      "epoch:  118  loss:  2.9465441703796387  accuracy:  1.0\n",
      "epoch:  119  loss:  2.946784734725952  accuracy:  1.0\n",
      "epoch:  120  loss:  2.946504831314087  accuracy:  1.0\n",
      "epoch:  121  loss:  2.946491003036499  accuracy:  1.0\n",
      "epoch:  122  loss:  2.9464621543884277  accuracy:  1.0\n",
      "epoch:  123  loss:  2.9464986324310303  accuracy:  1.0\n",
      "epoch:  124  loss:  2.946518659591675  accuracy:  1.0\n",
      "epoch:  125  loss:  2.94663667678833  accuracy:  1.0\n",
      "epoch:  126  loss:  2.946533203125  accuracy:  1.0\n",
      "epoch:  127  loss:  2.9464619159698486  accuracy:  1.0\n",
      "epoch:  128  loss:  2.94651460647583  accuracy:  1.0\n",
      "epoch:  129  loss:  2.946401357650757  accuracy:  1.0\n",
      "epoch:  130  loss:  2.946484088897705  accuracy:  1.0\n",
      "epoch:  131  loss:  2.9465208053588867  accuracy:  1.0\n",
      "epoch:  132  loss:  2.9464380741119385  accuracy:  1.0\n",
      "epoch:  133  loss:  2.9464328289031982  accuracy:  1.0\n",
      "epoch:  134  loss:  2.946463108062744  accuracy:  1.0\n",
      "epoch:  135  loss:  2.946564197540283  accuracy:  1.0\n",
      "epoch:  136  loss:  2.946451187133789  accuracy:  1.0\n",
      "epoch:  137  loss:  2.9463906288146973  accuracy:  1.0\n",
      "epoch:  138  loss:  2.9463913440704346  accuracy:  1.0\n",
      "epoch:  139  loss:  2.9463820457458496  accuracy:  1.0\n",
      "epoch:  140  loss:  2.9463882446289062  accuracy:  1.0\n",
      "epoch:  141  loss:  2.9463672637939453  accuracy:  1.0\n",
      "epoch:  142  loss:  2.9463844299316406  accuracy:  1.0\n",
      "epoch:  143  loss:  2.946375608444214  accuracy:  1.0\n",
      "epoch:  144  loss:  2.9463138580322266  accuracy:  1.0\n",
      "epoch:  145  loss:  2.9463818073272705  accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  146  loss:  2.9463796615600586  accuracy:  1.0\n",
      "epoch:  147  loss:  2.9464242458343506  accuracy:  1.0\n",
      "epoch:  148  loss:  2.9463846683502197  accuracy:  1.0\n",
      "epoch:  149  loss:  2.9463284015655518  accuracy:  1.0\n",
      "epoch:  150  loss:  2.9463672637939453  accuracy:  1.0\n",
      "epoch:  151  loss:  2.946363925933838  accuracy:  1.0\n",
      "epoch:  152  loss:  2.9464709758758545  accuracy:  1.0\n",
      "epoch:  153  loss:  2.9463753700256348  accuracy:  1.0\n",
      "epoch:  154  loss:  2.9463534355163574  accuracy:  1.0\n",
      "epoch:  155  loss:  2.9464495182037354  accuracy:  1.0\n",
      "epoch:  156  loss:  2.9463303089141846  accuracy:  1.0\n",
      "epoch:  157  loss:  2.9463748931884766  accuracy:  1.0\n",
      "epoch:  158  loss:  2.946347236633301  accuracy:  1.0\n",
      "epoch:  159  loss:  2.9463584423065186  accuracy:  1.0\n",
      "epoch:  160  loss:  2.946349859237671  accuracy:  1.0\n",
      "epoch:  161  loss:  2.946288824081421  accuracy:  1.0\n",
      "epoch:  162  loss:  2.9463934898376465  accuracy:  1.0\n",
      "epoch:  163  loss:  2.9462852478027344  accuracy:  1.0\n",
      "epoch:  164  loss:  2.946281671524048  accuracy:  1.0\n",
      "epoch:  165  loss:  2.9462287425994873  accuracy:  1.0\n",
      "epoch:  166  loss:  2.9463086128234863  accuracy:  1.0\n",
      "epoch:  167  loss:  2.9462971687316895  accuracy:  1.0\n",
      "epoch:  168  loss:  2.946225881576538  accuracy:  1.0\n",
      "epoch:  169  loss:  2.946258068084717  accuracy:  1.0\n",
      "epoch:  170  loss:  2.946288824081421  accuracy:  1.0\n",
      "epoch:  171  loss:  2.946347951889038  accuracy:  1.0\n",
      "epoch:  172  loss:  2.946296453475952  accuracy:  1.0\n",
      "epoch:  173  loss:  2.946242570877075  accuracy:  1.0\n",
      "epoch:  174  loss:  2.946338176727295  accuracy:  1.0\n",
      "epoch:  175  loss:  2.9462497234344482  accuracy:  1.0\n",
      "epoch:  176  loss:  2.946277379989624  accuracy:  1.0\n",
      "epoch:  177  loss:  2.9462356567382812  accuracy:  1.0\n",
      "epoch:  178  loss:  2.946233034133911  accuracy:  1.0\n",
      "epoch:  179  loss:  2.946259021759033  accuracy:  1.0\n",
      "epoch:  180  loss:  2.946284532546997  accuracy:  1.0\n",
      "epoch:  181  loss:  2.9462430477142334  accuracy:  1.0\n",
      "epoch:  182  loss:  2.946241617202759  accuracy:  1.0\n",
      "epoch:  183  loss:  2.946259021759033  accuracy:  1.0\n",
      "epoch:  184  loss:  2.9462461471557617  accuracy:  1.0\n",
      "epoch:  185  loss:  2.9462406635284424  accuracy:  1.0\n",
      "epoch:  186  loss:  2.9462125301361084  accuracy:  1.0\n",
      "epoch:  187  loss:  2.946270227432251  accuracy:  1.0\n",
      "epoch:  188  loss:  2.946202039718628  accuracy:  1.0\n",
      "epoch:  189  loss:  2.94625186920166  accuracy:  1.0\n",
      "epoch:  190  loss:  2.946289300918579  accuracy:  1.0\n",
      "epoch:  191  loss:  2.9462571144104004  accuracy:  1.0\n",
      "epoch:  192  loss:  2.9461872577667236  accuracy:  1.0\n",
      "epoch:  193  loss:  2.9462177753448486  accuracy:  1.0\n",
      "epoch:  194  loss:  2.946244478225708  accuracy:  1.0\n",
      "epoch:  195  loss:  2.946211338043213  accuracy:  1.0\n",
      "epoch:  196  loss:  2.9462926387786865  accuracy:  1.0\n",
      "epoch:  197  loss:  2.946237087249756  accuracy:  1.0\n",
      "epoch:  198  loss:  2.9461774826049805  accuracy:  1.0\n",
      "epoch:  199  loss:  2.9461874961853027  accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nX = torch.from_numpy(X_tfidf.todense()).float()\n",
    "ny = torch.from_numpy(y)\n",
    "\n",
    "\n",
    "nX_test = torch.from_numpy(X_test_tfidf.todense()).float()\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(200):\n",
    "    y_pred = model(nX)\n",
    "\n",
    "    loss = criterion(y_pred, ny)\n",
    "    \n",
    "    y_pred_a = torch.argmax(y_pred, dim=1).detach().numpy()\n",
    "    accuracy = accuracy_score(y_pred_a, ny)\n",
    "    \n",
    "    print('epoch: ', epoch,' loss: ', loss.item(),' accuracy: ', accuracy)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 38, 17, 43,  1, 10,  8, 30, 27, 27, 29, 20,  9, 22, 38, 44,  9,\n",
       "       45, 22, 46, 16, 32, 22, 13, 29, 48, 47, 24, 11, 42, 35, 35, 29, 15,\n",
       "        4, 27, 10, 30, 27, 49, 21,  4,  8, 13, 46, 32, 21, 31, 12, 23, 33,\n",
       "        7, 12, 15, 21, 41, 31, 23, 33,  1, 29, 45, 24, 40, 10, 11, 16, 30,\n",
       "       45, 39,  6, 30, 34, 36, 32, 29, 25, 21,  6, 32, 45, 37, 36, 38, 40,\n",
       "        1, 24, 32, 43, 38, 27, 31, 18, 39, 45, 37, 46, 18, 37, 45, 49, 26,\n",
       "       43, 44, 24, 35, 10, 46, 29, 35, 20, 40, 39, 44, 36, 49, 37, 35, 44,\n",
       "       31,  6, 30, 42, 31, 28, 26,  9, 25, 33, 18, 27,  1, 21, 12, 42,  8,\n",
       "       34, 44, 17, 22,  2, 12, 39, 37, 24, 38, 43, 20, 17,  1, 30, 42, 31,\n",
       "       45,  9, 25, 43,  1, 20, 29, 45, 48, 24, 47, 39, 29, 33, 46, 22, 17,\n",
       "        0, 29, 45, 34,  4, 18, 39, 21,  2, 29,  8, 46, 17,  9, 17, 17, 41,\n",
       "       30, 21, 21, 11, 22, 15, 17,  2, 26, 24, 20, 15,  6, 19,  2, 28, 31,\n",
       "       39, 24, 36, 15,  4, 12,  9, 41, 39, 44, 17, 15, 47, 11, 42, 37, 30,\n",
       "       10, 33, 21, 23, 10, 30, 36, 44, 37, 17,  1, 46, 48, 33, 31, 25, 26,\n",
       "       12, 28, 15,  4, 43, 38, 34, 16, 15, 28, 27, 46, 39, 36, 38, 16, 30,\n",
       "       16, 25, 21, 31, 39, 10,  7, 33, 26,  2, 17, 30,  5, 20, 46, 40, 14,\n",
       "       43, 49, 25, 30, 33,  9,  4, 24, 27, 26, 45, 41, 35, 10, 47, 40, 13,\n",
       "       38, 44, 45, 32,  1,  1,  6, 40,  8, 25, 33, 17,  1,  6,  1, 28,  6,\n",
       "        1, 25, 30, 39, 45, 44, 45, 41, 30, 42,  8, 24, 47, 21, 22,  9, 43,\n",
       "       36, 34, 20, 27,  8, 15, 41, 23, 30, 36, 19, 33, 12, 29,  6, 30, 32,\n",
       "       43, 24, 25, 45, 13, 22, 18, 11, 35,  5, 40, 24, 34, 48, 15, 20, 47,\n",
       "       11,  0, 28, 43, 47, 40, 21,  8, 33, 46, 49, 37, 40, 22, 41, 41,  2,\n",
       "       23, 19, 24, 17, 37,  9, 18, 36, 45, 42, 11,  0,  5, 37, 11, 40, 17,\n",
       "       20, 17, 34,  2, 30,  7, 27, 12, 18, 20, 36, 33, 18, 44, 19, 40, 13,\n",
       "       17, 13, 29, 47, 16, 14,  6, 10, 27, 10, 17, 41, 12,  0, 23, 32, 27,\n",
       "       28,  3, 25, 30, 26,  6, 39, 12, 14, 12,  9,  6, 20, 32, 31, 23,  7,\n",
       "        0,  8, 19, 42, 38, 44,  3, 16,  9,  2, 12, 30, 44, 14, 31, 11, 30,\n",
       "       33, 48,  4, 35, 47, 19, 49,  2, 12, 44, 18, 21, 23, 28, 16, 13, 24,\n",
       "       28, 28, 34, 14, 15, 28, 25, 49, 38, 43, 40, 26, 27,  1, 14, 21, 22,\n",
       "       45,  7, 15, 29, 13,  9, 39, 38,  4, 24, 10, 16,  5, 40, 37,  3, 16,\n",
       "       42, 38, 22, 47, 43,  6, 28,  4,  6, 27,  4, 45, 12, 33, 31, 35, 19,\n",
       "       18, 36, 47, 33, 44, 13, 49, 27,  2, 39, 38, 19, 42, 29, 19, 25, 32,\n",
       "       49, 43, 39, 29, 12, 19, 45, 20, 45, 24,  4, 36, 35,  0, 25, 21, 36,\n",
       "       39,  0, 24,  9, 44, 25, 46,  5, 30, 47,  6, 26, 44,  2, 41,  4, 47,\n",
       "       41, 31, 32,  6, 48, 33, 10, 37, 17, 25, 48, 38, 29, 27, 26, 32, 27,\n",
       "        8, 45, 43, 18,  0, 37, 23, 14, 39, 32, 24,  9, 28, 24, 47, 36, 23,\n",
       "       36, 42, 20, 13, 13, 27,  5,  4, 24,  5, 20,  1, 34, 38, 47, 10, 11,\n",
       "       47, 25, 44, 14, 46, 42,  6, 35, 23, 41, 36, 32, 25,  1, 24,  8, 29,\n",
       "       42, 20, 17,  8, 41, 37, 35, 34, 34,  3,  1, 40, 43, 48, 17, 26, 14,\n",
       "       43, 27, 37, 21, 41,  1, 25, 30, 19, 41, 18, 31, 15, 47, 18, 14,  6,\n",
       "       15,  9,  0, 25, 12, 43, 40, 40, 48, 48, 46,  9, 48, 10, 24, 41, 27,\n",
       "       35,  5,  1, 25,  6, 18, 10, 42, 22, 40, 43, 10,  2,  1,  7, 42,  8,\n",
       "       49, 45, 17,  3, 47, 25, 26,  8, 40, 13, 38, 20, 10,  9, 11,  0, 41,\n",
       "        1,  0, 35, 41,  5, 13,  0, 10, 48, 16, 17,  6, 40, 27, 35, 48, 26,\n",
       "        2, 37])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_output = model(nX_test)\n",
    "y_prediction = torch.argmax(y_output, dim=1).detach().numpy()\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Blankenship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Hayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Goonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Dent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Cholette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Comdet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Lawyeraau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Janson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class\n",
       "ID               \n",
       "750   Blankenship\n",
       "751         Hayes\n",
       "752        Goonan\n",
       "753          Dent\n",
       "754      Engineer\n",
       "...           ...\n",
       "1495     Cholette\n",
       "1496       Comdet\n",
       "1497    Lawyeraau\n",
       "1498        Grove\n",
       "1499       Janson\n",
       "\n",
       "[750 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_solution_test = pd.DataFrame(df_data_test['ID'])\n",
    "df_solution_test['Class'] = [class_index[p] for p in y_prediction]\n",
    "df_solution_test = df_solution_test.set_index('ID')\n",
    "\n",
    "df_solution_test.to_csv('solution_test_nn.csv')\n",
    "\n",
    "display(df_solution_test)\n",
    "\n",
    "\n",
    "# Class distribution\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "df_solution_test['Class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifierÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22700544e-05, 1.83871601e-04, 7.30216406e-03, ...,\n",
       "        6.58552736e-05, 3.79377350e-05, 3.01355075e-05],\n",
       "       [3.01771024e-05, 3.18205443e-04, 8.58248498e-04, ...,\n",
       "        2.61653207e-04, 2.00459522e-04, 7.06157847e-03],\n",
       "       [6.71203206e-05, 1.40674432e-03, 1.07459275e-03, ...,\n",
       "        2.44275431e-04, 1.68137236e-04, 4.17696232e-03],\n",
       "       ...,\n",
       "       [1.66431744e-03, 7.60264047e-04, 3.76949300e-03, ...,\n",
       "        1.24807555e-04, 1.71515396e-03, 2.26585706e-03],\n",
       "       [2.02023167e-02, 2.75908106e-04, 7.45770681e-01, ...,\n",
       "        1.85814713e-03, 1.01799229e-02, 1.70826913e-04],\n",
       "       [5.25433846e-03, 6.11026454e-04, 2.97593162e-03, ...,\n",
       "        1.32511065e-05, 3.53072768e-04, 1.26105351e-04]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC (TF-IDF)\n",
    "c = OneVsRestClassifier(SVC(C=9.75, kernel='rbf', probability=True))\n",
    "c.fit(X_tfidf, y)\n",
    "\n",
    "# Predict\n",
    "y_prediction_svc = c.predict_proba(X_test_tfidf)\n",
    "y_prediction_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_prediction_svc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0095498 , 0.0095498 , 0.01500682, ..., 0.        , 0.00682128,\n",
       "        0.00136426],\n",
       "       [0.02131783, 0.00581395, 0.02131783, ..., 0.00968992, 0.00387597,\n",
       "        0.01356589],\n",
       "       [0.00290684, 0.01733786, 0.01733786, ..., 0.01155857, 0.01444822,\n",
       "        0.0202275 ],\n",
       "       ...,\n",
       "       [0.00263817, 0.00527633, 0.03165799, ..., 0.        , 0.0079145 ,\n",
       "        0.00527633],\n",
       "       [0.05711541, 0.00316404, 0.08542914, ..., 0.01898425, 0.01898425,\n",
       "        0.00632808],\n",
       "       [0.0394921 , 0.00631723, 0.01737239, ..., 0.00473792, 0.00157931,\n",
       "        0.01421377]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForest (TF-IDF)\n",
    "c = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, max_depth=10, criterion='entropy'))\n",
    "c.fit(X_tfidf, y)\n",
    "\n",
    "# Predict\n",
    "y_prediction_rf = c.predict_proba(X_test_tfidf)\n",
    "y_prediction_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_prediction_rf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "def normalize_output(array_in):\n",
    "    norm = np.linalg.norm(array_in, ord=1)\n",
    "    return array_in/norm\n",
    "\n",
    "y_prediction_nn = normalize_output(y_output[0].detach().numpy())\n",
    "print(np.sum(y_prediction_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_max</th>\n",
       "      <th>nn_max_idx</th>\n",
       "      <th>rf_max</th>\n",
       "      <th>rf_max_idx</th>\n",
       "      <th>svc_max</th>\n",
       "      <th>svc_max_idx</th>\n",
       "      <th>vote_max</th>\n",
       "      <th>vote_max_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.952351</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.435220</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.387571</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.304616</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.066119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379854</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.412722</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.883773</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.495009</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.958397</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.254991</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.376456</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.907796</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.062778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304144</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.211941</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.158773</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.070093</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.269460</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.290001</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.772241</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.420014</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.606828</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.062022</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.496044</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.102872</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.523986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067974</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.349634</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.709551</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.770734</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.078965</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.673883</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.444617</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nn_max  nn_max_idx    rf_max  rf_max_idx   svc_max  svc_max_idx  \\\n",
       "9    0.952351        27.0  0.078200        47.0  0.435220         27.0   \n",
       "12   0.304616        34.0  0.066119         0.0  0.379854          3.0   \n",
       "15   0.883773        44.0  0.058106        29.0  0.495009         42.0   \n",
       "16   0.240137         0.0  0.039857        21.0  0.254991          4.0   \n",
       "19   0.907796        46.0  0.062778         0.0  0.304144         46.0   \n",
       "..        ...         ...       ...         ...       ...          ...   \n",
       "736  0.158773        16.0  0.070093        33.0  0.269460         24.0   \n",
       "744  0.772241        14.0  0.062356        16.0  0.420014         16.0   \n",
       "745  0.606828        42.0  0.062022        28.0  0.496044         42.0   \n",
       "746  0.523986         1.0  0.067974        23.0  0.349634         34.0   \n",
       "749  0.770734        37.0  0.078965        13.0  0.673883         37.0   \n",
       "\n",
       "     vote_max  vote_max_idx  \n",
       "9    1.387571          27.0  \n",
       "12   0.412722           3.0  \n",
       "15   0.958397          44.0  \n",
       "16   0.376456           4.0  \n",
       "19   1.211941          46.0  \n",
       "..        ...           ...  \n",
       "736  0.290001          24.0  \n",
       "744  0.948736          14.0  \n",
       "745  1.102872          42.0  \n",
       "746  0.709551           1.0  \n",
       "749  1.444617          37.0  \n",
       "\n",
       "[247 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_prediction_vote = []\n",
    "\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "for i in range(0, len(y_prediction_rf)):\n",
    "    y_prediction_svc_v = y_prediction_svc[i]\n",
    "    max_idx_svc = np.argmax(y_prediction_svc_v)\n",
    "    max_pred_svc = y_prediction_svc_v[max_idx_svc]\n",
    "    \n",
    "    y_prediction_rf_v = y_prediction_rf[i]\n",
    "    max_idx_rf = np.argmax(y_prediction_rf_v)\n",
    "    max_pred_rf = y_prediction_rf_v[max_idx_rf]\n",
    "    \n",
    "    \n",
    "    y_prediction_nn_v = normalize_output(y_output[i].detach().numpy())\n",
    "    max_idx_nn = np.argmax(y_prediction_nn_v)\n",
    "    max_pred_nn = y_prediction_nn_v[max_idx_nn]\n",
    "\n",
    "    a = 1.0 # weight SVC\n",
    "    b = 0.0 # weight RF\n",
    "    c = 1.0 # weight NN\n",
    "    \n",
    "    y_prediction_vote_v = [y_prediction_svc_v[idx] * a + y_prediction_rf_v[idx] * b + y_prediction_nn_v[idx] * c for idx in range(0, len(y_prediction_rf_v))]\n",
    "    \n",
    "    max_idx_vote = np.argmax(y_prediction_vote_v)\n",
    "    max_pred_vote = y_prediction_vote_v[max_idx_vote]\n",
    "    \n",
    "    y_prediction_vote.append(max_idx_vote)\n",
    "    \n",
    "    df_voting = df_voting.append({\n",
    "        'svc_max_idx': max_idx_svc,\n",
    "        'svc_max': max_pred_svc,\n",
    "        'rf_max_idx': max_idx_rf,\n",
    "        'rf_max': max_pred_rf,\n",
    "        'nn_max_idx': max_idx_nn,\n",
    "        'nn_max': max_pred_nn,\n",
    "        'vote_max_idx': max_idx_vote,\n",
    "        'vote_max': max_pred_vote\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "df_voting.to_csv('voting_test.csv')\n",
    "\n",
    "display(df_voting[df_voting['nn_max_idx'] != df_voting['rf_max_idx']])\n",
    "\n",
    "df_voting[df_voting['nn_max_idx'] != df_voting['rf_max_idx']].to_csv('voting_test_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Blankenship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Hayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Goonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Dent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Lawyeraau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Janson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class\n",
       "ID               \n",
       "750   Blankenship\n",
       "751         Hayes\n",
       "752        Goonan\n",
       "753          Dent\n",
       "754      Engineer\n",
       "...           ...\n",
       "1495         Corn\n",
       "1496     Engineer\n",
       "1497    Lawyeraau\n",
       "1498        Grove\n",
       "1499       Janson\n",
       "\n",
       "[750 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_voting_solution_test = pd.DataFrame(df_data_test['ID'])\n",
    "df_voting_solution_test['Class'] = [class_index[p] for p in y_prediction_vote]\n",
    "df_voting_solution_test = df_voting_solution_test.set_index('ID')\n",
    "df_voting_solution_test\n",
    "\n",
    "df_voting_solution_test.to_csv('solution_test_vote.csv')\n",
    "\n",
    "display(df_voting_solution_test)\n",
    "\n",
    "\n",
    "# Class distribution\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "df_voting_solution_test['Class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
